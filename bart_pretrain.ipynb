{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Serbernari/NER-summarization/blob/main/bart_pretrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrdctq4-jvyW",
        "outputId": "971769e5-851e-403a-ebf1-aab5106ad61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERY USEFULL https://github.com/jessevig/bertviz#encoder-decoder-models-bart-t5-etc"
      ],
      "metadata": {
        "id": "m8suuBcKIoae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wfyD30dFU2P",
        "outputId": "2202cb86-502b-4719-9120-f325a91497de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mS8vX0w1Reb",
        "outputId": "80080fdb-616a-4c4b-de44-46e08441251a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (4.2.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.4.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0MwTfPyhE4m"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import jsonlines\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW, lr_scheduler\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVs871VXSI9n"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daNES9eLSMZP",
        "outputId": "06da636e-c6f3-4c6c-8400-e2ae898b768c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Diplom/Summarization/arxiv-dataset.zip\n",
            "   creating: arxiv-dataset/\n",
            "  inflating: __MACOSX/._arxiv-dataset  \n",
            "  inflating: arxiv-dataset/train.txt  \n",
            "  inflating: __MACOSX/arxiv-dataset/._train.txt  \n",
            "  inflating: arxiv-dataset/vocab     \n",
            "  inflating: __MACOSX/arxiv-dataset/._vocab  \n",
            "  inflating: arxiv-dataset/test.txt  \n",
            "  inflating: __MACOSX/arxiv-dataset/._test.txt  \n",
            "  inflating: arxiv-dataset/val.txt   \n",
            "  inflating: __MACOSX/arxiv-dataset/._val.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip  /content/drive/MyDrive/Diplom/Summarization/arxiv-dataset.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUJSMv2LVUVD"
      },
      "source": [
        "creating target data for MLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sr8caLxS9MX"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/Diplom/Pretraining/target.txt\", 'w+') as output: #\"</s>\"? won't it get cut? wont tokenizer add it?\n",
        "  for filename in [\"/content/arxiv-dataset/test.txt\",\n",
        "                  \"/content/arxiv-dataset/train.txt\",\n",
        "                  \"/content/arxiv-dataset/val.txt\"]:\n",
        "    with open(filename) as f:\n",
        "        for i, line in enumerate(f):\n",
        "          data = json.loads(line)              \n",
        "          article_text = data['article_text']\n",
        "          article_text = ' '.join(article_text)\n",
        "          article_text+=\"</s>\"\n",
        "          article_text+=\"\\n\"\n",
        "          output.write(article_text)\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RCFXL8_SMfI"
      },
      "outputs": [],
      "source": [
        "def generate_input(example): #чтоб число токенов совпадало - сложносоставные слова это несколько масок.\n",
        "#TODO: random masking of other words\n",
        "  NER_mask_proba = 0.5\n",
        "  tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"/content/drive/MyDrive/Diplom/NER/outputs/checkpoint-1372-epoch-7\")\n",
        "  nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0) \n",
        "\n",
        "  ner_results = nlp(example) #need to get rid of this list - unlist thing \n",
        "  output = []\n",
        "    \n",
        "  for i in range(len(ner_results)): # HERE LAYS RANDOM\n",
        "    ents = set(x['word'].replace(\"Ġ\", '') for x in ner_results[i] if x['entity'] != 'LABEL_0' and len(x[\"word\"]) > 3 and random.random() >= NER_mask_proba) #select all words that are entities and not in cathegory \"OTHER\"\n",
        "    words = [\"<mask>\" if x in ents else x for x in example[i].split()]\n",
        "    output.append(\" \".join(words))\n",
        "\n",
        "  return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gM7ROmV6rXu"
      },
      "outputs": [],
      "source": [
        "#generate_input([\"this is experiment example\", \"with multiple strings attached method\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b2XxMpOTEoh",
        "outputId": "3b1b6746-5a93-481b-9b25-79ec086d784f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on /content/arxiv-dataset/test.txt. Lines in file: 6440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6440it [07:49, 13.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on /content/arxiv-dataset/train.txt. Lines in file: 203037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "203037it [3:24:27, 16.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on /content/arxiv-dataset/val.txt. Lines in file: 6436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6436it [06:24, 16.73it/s]\n"
          ]
        }
      ],
      "source": [
        "batch = []\n",
        "batch_size = 100000\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Diplom/Pretraining/masked.txt\", 'w+') as output:\n",
        "  for filename in [\"/content/arxiv-dataset/test.txt\",\n",
        "                   \"/content/arxiv-dataset/train.txt\",\n",
        "                   \"/content/arxiv-dataset/val.txt\"]:\n",
        "    file_len = sum(1 for line in open(filename))\n",
        "    print(f\"Working on {filename}. Lines in file: {file_len}\")\n",
        "    with open(filename) as f:\n",
        "        for i, line in tqdm(enumerate(f, 1)):\n",
        "          data = json.loads(line)              \n",
        "          article_text = data['article_text']\n",
        "          article_text = ' '.join(article_text)\n",
        "          batch.append(article_text)\n",
        "          if len(batch) >= batch_size or i == file_len:\n",
        "            masked_batch = generate_input(batch)\n",
        "            for text in masked_batch:\n",
        "              text+=\"\\n\"\n",
        "              output.write(text)\n",
        "            batch.clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhswwCMGTEuf",
        "outputId": "621d7c59-6c00-4b31-b80e-28ee226c4093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for about 20 years the problem of properties of short - term changes of solar activity has been considered extensively . many investigators studied the short - term periodicities of the various indices of solar activity . several periodicities were detected , but the periodicities about 155 days and from the interval of @xmath3 $ ] days ( @xmath4 $ ] years ) are mentioned most often . first of them was discovered by @xcite in the occurence rate of gamma - ray flares detected by the gamma - ray spectrometer aboard the _ solar maximum mission ( smm ) . this periodicity was confirmed for other solar flares data and for the same time period @xcite . it was also found in proton flares during solar cycles 19 and 20 @xcite , but it was not found in the solar flares data during solar cycles 22 @xcite . _    several autors confirmed above results for the daily sunspot area data . @xcite studied the sunspot data from 18741984 . she found the 155-day periodicity in data records from 31 years . this periodicity is always characteristic for one of the solar hemispheres ( the southern hemisphere for cycles 1215 and the northern hemisphere for cycles 1621 ) . moreover , it is only present during epochs of maximum activity ( in episodes of 13 years ) . similarinvestigationswerecarriedoutby + @xcite . they applied the same power spectrum method as lean , but the daily sunspot area data ( cycles 1221 ) were divided into 10 shorter time series . the periodicities were searched for the frequency interval 57115 nhz ( 100200 days ) and for each of 10 time series . the authors showed that the periodicity between 150160 days is statistically significant during all cycles from 16 to 21 . the considered peaks were remained unaltered after removing the 11-year cycle and applying the power spectrum analysis . @xcite used the wavelet technique for the daily sunspot areas between 1874 and 1993 . they determined the epochs of appearance of this periodicity and concluded that it presents around the maximum activity period in cycles 16 to 21 . moreover , the power of this periodicity started growing at cycle 19 , decreased in cycles 20 and 21 and disappered after cycle 21 . similaranalyseswerepresentedby + @xcite , but for sunspot number , solar wind plasma , interplanetary magnetic field and geomagnetic activity index @xmath5 . during 1964 - 2000 the sunspot number wavelet power of periods less than one year shows a cyclic evolution with the phase of the solar cycle.the 154-day period is prominent and its strenth is stronger around the 1982 - 1984 interval in almost all solar wind parameters . the existence of the 156-day periodicity in sunspot data were confirmed by @xcite . they considered the possible relation between the 475-day ( 1.3-year ) and 156-day periodicities . the 475-day ( 1.3-year ) periodicity was also detected in variations of the interplanetary magnetic field , geomagnetic activity helioseismic data and in the solar wind speed @xcite . @xcite concluded that the region of larger wavelet power shifts from 475-day ( 1.3-year ) period to 620-day ( 1.7-year ) period and then back to 475-day ( 1.3-year ) . the periodicities from the interval @xmath6 $ ] days ( @xmath4 $ ] years ) have been considered from 1968 . @xcite mentioned a 16.3-month ( 490-day ) periodicity in the sunspot numbers and in the geomagnetic data . @xcite analysed the occurrence rate of major flares during solar cycles 19 . they found a 18-month ( 540-day ) periodicity in flare rate of the norhern hemisphere . @xcite confirmed this result for the @xmath7 flare data for solar cycles 20 and 21 and found a peak in the power spectra near 510540 days . @xcite found a 17-month ( 510-day ) periodicity of sunspot groups and their areas from 1969 to 1986 . these authors concluded that the length of this period is variable and the reason of this periodicity is still not understood . @xcite and + @xcite obtained statistically significant peaks of power at around 158 days for daily sunspot data from 1923 - 1933 ( cycle 16 ) . in this paper the problem of the existence of this periodicity for sunspot data from cycle 16 is considered . the daily sunspot areas , the mean sunspot areas per carrington rotation , the monthly sunspot numbers and their fluctuations , which are obtained after removing the 11-year cycle are analysed . in section 2 the properties of the power spectrum methods are described . in section 3 a new approach to the problem of aliases in the power spectrum analysis is presented . in section 4 numerical results of the new method of the diagnosis of an echo - effect for sunspot area data are discussed . in section 5 the problem of the existence of the periodicity of about 155 days during the maximum activity period for sunspot data from the whole solar disk and from each solar hemisphere separately is considered . to find periodicities in a given time series the power spectrum analysis is applied . in this paper two methods are used : the fast fourier transformation algorithm with the hamming window function ( fft ) and the blackman - tukey ( bt ) power spectrum method @xcite . the bt method is used for the diagnosis of the reasons of the existence of peaks , which are obtained by the fft method . the bt method consists in the smoothing of a cosine transform of an autocorrelation function using a 3-point weighting average . such an estimator is consistent and unbiased . moreover , the peaks are uncorrelated and their sum is a variance of a considered time series . the main disadvantage of this method is a weak resolution of the periodogram points , particularly for low frequences . for example , if the autocorrelation function is evaluated for @xmath8 , then the distribution points in the time domain are : @xmath9 thus , it is obvious that this method should not be used for detecting low frequency periodicities with a fairly good resolution . however , because of an application of the autocorrelation function , the bt method can be used to verify a reality of peaks which are computed using a method giving the better resolution ( for example the fft method ) . it is valuable to remember that the power spectrum methods should be applied very carefully . the difficulties in the interpretation of significant peaks could be caused by at least four effects : a sampling of a continuos function , an echo - effect , a contribution of long - term periodicities and a random noise . first effect exists because periodicities , which are shorter than the sampling interval , may mix with longer periodicities . in result , this effect can be reduced by an decrease of the sampling interval between observations . the echo - effect occurs when there is a latent harmonic of frequency @xmath10 in the time series , giving a spectral peak at @xmath10 , and also periodic terms of frequency @xmath11 etc . this may be detected by the autocorrelation function for time series with a large variance . time series often contain long - term periodicities , that influence short - term peaks . they could rise periodogram s peaks at lower frequencies . however , it is also easy to notice the influence of the long - term periodicities on short - term peaks in the graphs of the autocorrelation functions . this effect is observed for the time series of solar activity indexes which are limited by the 11-year cycle .    to find statistically significant periodicities it is reasonable to use the autocorrelation function and the power spectrum method with a high resolution . in the case of a stationary time series they give similar results . moreover , for a stationary time series with the mean zero the fourier transform is equivalent to the cosine transform of an autocorrelation function @xcite . thus , after a comparison of a periodogram with an appropriate autocorrelation function one can detect peaks which are in the graph of the first function and do not exist in the graph of the second function . the reasons of their existence could be explained by the long - term periodicities and the echo - effect . below method enables one to detect these effects . ( solid line ) and the 95% confidence level basing on thered noise ( dotted line ) . the periodogram values are presented on the left axis . the lower curve illustrates the autocorrelation function of the same time series ( solid line ) . the dotted lines represent two standard errors of the autocorrelation function . the dashed horizontal line shows the zero level . the autocorrelation values are shown in the right axis . ]     because the statistical tests indicate that the time series is a white noise the confidence level is not marked . ]    . ] the method of the diagnosis of an echo - effect in the power spectrum ( de ) consists in an analysis of a periodogram of a given time series computed using the bt method . the bt method bases on the cosine transform of the autocorrelation function which creates peaks which are in the periodogram , but not in the autocorrelation function . the de method is used for peaks which are computed by the fft method ( with high resolution ) and are statistically significant . the time series of sunspot activity indexes with the spacing interval one rotation or one month contain a markov - type persistence , which means a tendency for the successive values of the time series to remember their antecendent values . thus , i use a confidence level basing on the red noise of markov @xcite for the choice of the significant peaks of the periodogram computed by the fft method . when a time series does not contain the markov - type persistence i apply the fisher test and the kolmogorov - smirnov test at the significance level @xmath12 @xcite to verify a statistically significance of periodograms peaks . the fisher test checks the null hypothesis that the time series is white noise agains the alternative hypothesis that the time series contains an added deterministic periodic component of unspecified frequency . because the fisher test tends to be severe in rejecting peaks as insignificant the kolmogorov - smirnov test is also used . the de method analyses raw estimators of the power spectrum . they are given as follows    @xmath13    for @xmath14 + where @xmath15 for @xmath16 + @xmath17 is the length of the time series @xmath18 and @xmath19 is the mean value . the first term of the estimator @xmath20 is constant . the second term takes two values ( depending on odd or even @xmath21 ) which are not significant because @xmath22 for large m. thus , the third term of ( 1 ) should be analysed . looking for intervals of @xmath23 for which @xmath24 has the same sign and different signs one can find such parts of the function @xmath25 which create the value @xmath20 . let the set of values of the independent variable of the autocorrelation function be called @xmath26 and it can be divided into the sums of disjoint sets : @xmath27 where + @xmath28 + @xmath29 @xmath30 @xmath31 + @xmath32 + @xmath33 @xmath34 @xmath35 @xmath36 @xmath37 @xmath38 @xmath39 @xmath40    well , the set @xmath41 contains all integer values of @xmath23 from the interval of @xmath42 for which the autocorrelation function and the cosinus function with the period @xmath43 $ ] are positive . the index @xmath44 indicates successive parts of the cosinus function for which the cosinuses of successive values of @xmath23 have the same sign . however , sometimes the set @xmath41 can be empty . for example , for @xmath45 and @xmath46 the set @xmath47 should contain all @xmath48 $ ] for which @xmath49 and @xmath50 , but for such values of @xmath23 the values of @xmath51 are negative . thus , the set @xmath47 is empty .    . the periodogram values are presented on the left axis . the lower curve illustrates the autocorrelation function of the same time series . the autocorrelation values are shown in the right axis . ] let us take into consideration all sets \\{@xmath52 } , \\{@xmath53 } and \\{@xmath41 } which are not empty . because numberings and power of these sets depend on the form of the autocorrelation function of the given time series , it is impossible to establish them arbitrary . thus , the sets of appropriate indexes of the sets \\{@xmath52 } , \\{@xmath53 } and \\{@xmath41 } are called @xmath54 , @xmath55 and @xmath56 respectively . for example the set @xmath56 contains all @xmath44 from the set @xmath57 for which the sets @xmath41 are not empty . to separate quantitatively in the estimator @xmath20 the positive contributions which are originated by the cases described by the formula ( 5 ) from the cases which are described by the formula ( 3 ) the following indexes are introduced : @xmath58 @xmath59 @xmath60 @xmath61 where @xmath62 @xmath63 @xmath64 taking for the empty sets \\{@xmath53 } and \\{@xmath41 } the indices @xmath65 and @xmath66 equal zero . the index @xmath65 describes a percentage of the contribution of the case when @xmath25 and @xmath51 are positive to the positive part of the third term of the sum ( 1 ) . the index @xmath66 describes a similar contribution , but for the case when the both @xmath25 and @xmath51 are simultaneously negative . thanks to these one can decide which the positive or the negative values of the autocorrelation function have a larger contribution to the positive values of the estimator @xmath20 . when the difference @xmath67 is positive , the statement the @xmath21-th peak really exists can not be rejected . thus , the following formula should be satisfied : @xmath68    because the @xmath21-th peak could exist as a result of the echo - effect , it is necessary to verify the second condition :    @xmath69\\in c_m.\\ ] ]    . the periodogram values are presented on the left axis . the lower curve illustrates the autocorrelation function of the same time series ( solid line ) . the dotted lines represent two standard errors of the autocorrelation function . the dashed horizontal line shows the zero level . the autocorrelation values are shown in the right axis . ]    to verify the implication ( 8) firstly it is necessary to evaluate the sets @xmath41 for @xmath70 of the values of @xmath23 for which the autocorrelation function and the cosine function with the period @xmath71 $ ] are positive and the sets @xmath72 of values of @xmath23 for which the autocorrelation function and the cosine function with the period @xmath43 $ ] are negative . secondly , a percentage of the contribution of the sum of products of positive values of @xmath25 and @xmath51 to the sum of positive products of the values of @xmath25 and @xmath51 should be evaluated . as a result the indexes @xmath65 for each set @xmath41 where @xmath44 is the index from the set @xmath56 are obtained . thirdly , from all sets @xmath41 such that @xmath70 the set @xmath73 for which the index @xmath65 is the greatest should be chosen .    the implication ( 8) is true when the set @xmath73 includes the considered period @xmath43 $ ] . this means that the greatest contribution of positive values of the autocorrelation function and positive cosines with the period @xmath43 $ ] to the periodogram value @xmath20 is caused by the sum of positive products of @xmath74 for each @xmath75-\\frac{m}{2k},[\\frac{2m}{k}]+\\frac{m}{2k})$ ] .    when the implication ( 8) is false , the peak @xmath20 is mainly created by the sum of positive products of @xmath74 for each @xmath76-\\frac{m}{2k},\\big [ \\frac{2m}{n}\\big ] + \\frac{m}{2k } \\big ) $ ] , where @xmath77 is a multiple or a divisor of @xmath21 . it is necessary to add , that the de method should be applied to the periodograms peaks , which probably exist because of the echo - effect . it enables one to find such parts of the autocorrelation function , which have the significant contribution to the considered peak . the fact , that the conditions ( 7 ) and ( 8) are satisfied , can unambiguously decide about the existence of the considered periodicity in the given time series , but if at least one of them is not satisfied , one can doubt about the existence of the considered periodicity . thus , in such cases the sentence the peak can not be treated as true should be used .    using the de method it is necessary to remember about the power of the set @xmath78 . if @xmath79 is too large , errors of an autocorrelation function estimation appear . they are caused by the finite length of the given time series and as a result additional peaks of the periodogram occur . if @xmath79 is too small , there are less peaks because of a low resolution of the periodogram . in applications @xmath80 is used . in order to evaluate the value @xmath79 the fft method is used . the periodograms computed by the bt and the fft method are compared . the conformity of them enables one to obtain the value @xmath79 .    . the fft periodogram values are presented on the left axis . the lower curve illustrates the bt periodogram of the same time series ( solid line and large black circles ) . the bt periodogram values are shown in the right axis . ] in this paper the sunspot activity data ( august 1923 - october 1933 ) provided by the greenwich photoheliographic results ( gpr ) are analysed . firstly , i consider the monthly sunspot number data . to eliminate the 11-year trend from these data , the consecutively smoothed monthly sunspot number @xmath81 is subtracted from the monthly sunspot number @xmath82 where the consecutive mean @xmath83 is given by @xmath84 the values @xmath83 for @xmath85 and @xmath86 are calculated using additional data from last six months of cycle 15 and first six months of cycle 17 .    because of the north - south asymmetry of various solar indices @xcite , the sunspot activity is considered for each solar hemisphere separately . analogously to the monthly sunspot numbers , the time series of sunspot areas in the northern and southern hemispheres with the spacing interval @xmath87 rotation are denoted . in order to find periodicities , the following time series are used : + @xmath88   + @xmath89    + @xmath90     + in the lower part of figure [ f1 ] the autocorrelation function of the time series for the northern hemisphere @xmath88 is shown . it is easy to notice that the prominent peak falls at 17 rotations interval ( 459 days ) and @xmath25 for @xmath91 $ ] rotations ( [ 81 , 162 ] days ) are significantly negative . the periodogram of the time series @xmath88 ( see the upper curve in figures [ f1 ] ) does not show the significant peaks at @xmath92 rotations ( 135 , 162 days ) , but there is the significant peak at @xmath93 ( 243 days ) . the peaks at @xmath94 are close to the peaks of the autocorrelation function . thus , the result obtained for the periodicity at about @xmath0 days are contradict to the results obtained for the time series of daily sunspot areas @xcite .    for the southern hemisphere ( the lower curve in figure [ f2 ] ) @xmath25 for @xmath95 $ ] rotations ( [ 54 , 189 ] days ) is not positive except @xmath96 ( 135 days ) for which @xmath97 is not statistically significant . the upper curve in figures [ f2 ] presents the periodogram of the time series @xmath89 . this time series does not contain a markov - type persistence . moreover , the kolmogorov - smirnov test and the fisher test do not reject a null hypothesis that the time series is a white noise only . this means that the time series do not contain an added deterministic periodic component of unspecified frequency . the autocorrelation function of the time series @xmath90 ( the lower curve in figure [ f3 ] ) has only one statistically significant peak for @xmath98 months ( 480 days ) and negative values for @xmath99 $ ] months ( [ 90 , 390 ] days ) . however , the periodogram of this time series ( the upper curve in figure [ f3 ] ) has two significant peaks the first at 15.2 and the second at 5.3 months ( 456 , 159 days ) . thus , the periodogram contains the significant peak , although the autocorrelation function has the negative value at @xmath100 months .    to explain these problems two following time series of daily sunspot areas are considered : + @xmath101   + @xmath102     + where @xmath103    the values @xmath104 for @xmath105 and @xmath106 are calculated using additional daily data from the solar cycles 15 and 17 .     and the cosine function for @xmath45 ( the period at about 154 days ) . the horizontal line ( dotted line ) shows the zero level . the vertical dotted lines evaluate the intervals where the sets @xmath107 ( for @xmath108 ) are searched . the percentage values show the index @xmath65 for each @xmath41 for the time series @xmath102 ( in parentheses for the time series @xmath101 ) . in the right bottom corner the values of @xmath65 for the time series @xmath102 , for @xmath109 are written . ] ( the 500-day period ) ]    the comparison of the functions @xmath25 of the time series @xmath101 ( the lower curve in figure [ f4 ] ) and @xmath102 ( the lower curve in figure [ f5 ] ) suggests that the positive values of the function @xmath110 of the time series @xmath101 in the interval of @xmath111 $ ] days could be caused by the 11-year cycle . this effect is not visible in the case of periodograms of the both time series computed using the fft method ( see the upper curves in figures [ f4 ] and [ f5 ] ) or the bt method ( see the lower curve in figure [ f6 ] ) . moreover , the periodogram of the time series @xmath102 has the significant values at @xmath112 days , but the autocorrelation function is negative at these points . @xcite showed that the lomb - scargle periodograms for the both time series ( see @xcite , figures 7 a - c ) have a peak at 158.8 days which stands over the fap level by a significant amount . using the de method the above discrepancies are obvious . to establish the @xmath79 value the periodograms computed by the fft and the bt methods are shown in figure [ f6 ] ( the upper and the lower curve respectively ) . for @xmath46 and for periods less than 166 days there is a good comformity of the both periodograms ( but for periods greater than 166 days the points of the bt periodogram are not linked because the bt periodogram has much worse resolution than the fft periodogram ( no one know how to do it ) ) . for @xmath46 and @xmath113 the value of @xmath21 is 13 ( @xmath71=153 $ ] ) . the inequality ( 7 ) is satisfied because @xmath114 . this means that the value of @xmath115 is mainly created by positive values of the autocorrelation function . the implication ( 8) needs an evaluation of the greatest value of the index @xmath65 where @xmath70 , but the solar data contain the most prominent period for @xmath116 days because of the solar rotation . thus , although @xmath117 for each @xmath118 , all sets @xmath41 ( see ( 5 ) and ( 6 ) ) without the set @xmath119 ( see ( 4 ) ) , which contains @xmath120 $ ] , are considered . this situation is presented in figure [ f7 ] . in this figure two curves @xmath121 and @xmath122 are plotted . the vertical dotted lines evaluate the intervals where the sets @xmath107 ( for @xmath123 ) are searched . for such @xmath41 two numbers are written : in parentheses the value of @xmath65 for the time series @xmath101 and above it the value of @xmath65 for the time series @xmath102 . to make this figure clear the curves are plotted for the set @xmath124 only . ( in the right bottom corner information about the values of @xmath65 for the time series @xmath102 , for @xmath109 are written . ) the implication ( 8) is not true , because @xmath125 for @xmath126 . therefore , @xmath43=153\\notin c_6=[423,500]$ ] . moreover , the autocorrelation function for @xmath127 $ ] is negative and the set @xmath128 is empty . thus , @xmath129 . on the basis of these information one can state , that the periodogram peak at @xmath130 days of the time series @xmath102 exists because of positive @xmath25 , but for @xmath23 from the intervals which do not contain this period . looking at the values of @xmath65 of the time series @xmath101 , one can notice that they decrease when @xmath23 increases until @xmath131 . this indicates , that when @xmath23 increases , the contribution of the 11-year cycle to the peaks of the periodogram decreases . an increase of the value of @xmath65 is for @xmath132 for the both time series , although the contribution of the 11-year cycle for the time series @xmath101 is insignificant . thus , this part of the autocorrelation function ( @xmath133 for the time series @xmath102 ) influences the @xmath21-th peak of the periodogram . this suggests that the periodicity at about 155 days is a harmonic of the periodicity from the interval of @xmath1 $ ] days . ( solid line ) and consecutively smoothed sunspot areas of the one rotation time interval @xmath134 ( dotted line ) . both indexes are presented on the left axis . the lower curve illustrates fluctuations of the sunspot areas @xmath135 . the dotted and dashed horizontal lines represent levels zero and @xmath136 respectively . the fluctuations are shown on the right axis . ] the described reasoning can be carried out for other values of the periodogram . for example , the condition ( 8) is not satisfied for @xmath137 ( 250 , 222 , 200 days ) . moreover , the autocorrelation function at these points is negative . these suggest that there are not a true periodicity in the interval of [ 200 , 250 ] days . it is difficult to decide about the existence of the periodicities for @xmath138 ( 333 days ) and @xmath139 ( 286 days ) on the basis of above analysis . the implication ( 8) is not satisfied for @xmath139 and the condition ( 7 ) is not satisfied for @xmath138 , although the function @xmath25 of the time series @xmath102 is significantly positive for @xmath140 . the conditions ( 7 ) and ( 8) are satisfied for @xmath141 ( figure [ f8 ] ) and @xmath142 . therefore , it is possible to exist the periodicity from the interval of @xmath1 $ ] days . similar results were also obtained by @xcite for daily sunspot numbers and daily sunspot areas . she considered the means of three periodograms of these indexes for data from @xmath143 years and found statistically significant peaks from the interval of @xmath1 $ ] ( see @xcite , figure 2 ) . @xcite studied sunspot areas from 1876 - 1999 and sunspot numbers from 1749 - 2001 with the help of the wavelet transform . they pointed out that the 154 - 158-day period could be the third harmonic of the 1.3-year ( 475-day ) period . moreover , the both periods fluctuate considerably with time , being stronger during stronger sunspot cycles . therefore , the wavelet analysis suggests a common origin of the both periodicities . this conclusion confirms the de method result which indicates that the periodogram peak at @xmath144 days is an alias of the periodicity from the interval of @xmath1 $ ] in order to verify the existence of the periodicity at about 155 days i consider the following time series : + @xmath145     + @xmath146    + @xmath147   + the value @xmath134 is calculated analogously to @xmath83 ( see sect . the values @xmath148 and @xmath149 are evaluated from the formula ( 9 ) . in the upper part of figure [ f9 ] the time series of sunspot areas @xmath150 of the one rotation time interval from the whole solar disk and the time series of consecutively smoothed sunspot areas @xmath151 are showed . in the lower part of figure [ f9 ] the time series of sunspot area fluctuations @xmath145 is presented . on the basis of these data the maximum activity period of cycle 16 is evaluated . it is an interval between two strongest fluctuations e.a . @xmath152 $ ] rotations . the length of the time interval @xmath153 is 54 rotations . if the about @xmath0-day ( 6 solar rotations ) periodicity existed in this time interval and it was characteristic for strong fluctuations from this time interval , 10 local maxima in the set of @xmath154 would be seen . then it should be necessary to find such a value of p for which @xmath155 for @xmath156 and the number of the local maxima of these values is 10 . as it can be seen in the lower part of figure [ f9 ] this is for the case of @xmath157 ( in this figure the dashed horizontal line is the level of @xmath158 ) . figure [ f10 ] presents nine time distances among the successive fluctuation local maxima and the horizontal line represents the 6-rotation periodicity . it is immediately apparent that the dispersion of these points is 10 and it is difficult to find even few points which oscillate around the value of 6 . such an analysis was carried out for smaller and larger @xmath136 and the results were similar . therefore , the fact , that the about @xmath0-day periodicity exists in the time series of sunspot area fluctuations during the maximum activity period is questionable .    . the horizontal line represents the 6-rotation ( 162-day ) period . ]    ]    ]    to verify again the existence of the about @xmath0-day periodicity during the maximum activity period in each solar hemisphere separately , the time series @xmath88 and @xmath89 were also cut down to the maximum activity period ( january 1925december 1930 ) . the comparison of the autocorrelation functions of these time series with the appriopriate autocorrelation functions of the time series @xmath88 and @xmath89 , which are computed for the whole 11-year cycle ( the lower curves of figures [ f1 ] and [ f2 ] ) , indicates that there are not significant differences between them especially for @xmath23=5 and 6 rotations ( 135 and 162 days ) ) . this conclusion is confirmed by the analysis of the time series @xmath146 for the maximum activity period . the autocorrelation function ( the lower curve of figure [ f11 ] ) is negative for the interval of [ 57 , 173 ] days , but the resolution of the periodogram is too low to find the significant peak at @xmath159 days . the autocorrelation function gives the same result as for daily sunspot area fluctuations from the whole solar disk ( @xmath160 ) ( see also the lower curve of figures [ f5 ] ) . in the case of the time series @xmath89 @xmath161 is zero for the fluctuations from the whole solar cycle and it is almost zero ( @xmath162 ) for the fluctuations from the maximum activity period . the value @xmath163 is negative . similarly to the case of the northern hemisphere the autocorrelation function and the periodogram of southern hemisphere daily sunspot area fluctuations from the maximum activity period @xmath147 are computed ( see figure [ f12 ] ) . the autocorrelation function has the statistically significant positive peak in the interval of [ 155 , 165 ] days , but the periodogram has too low resolution to decide about the possible periodicities . the correlative analysis indicates that there are positive fluctuations with time distances about @xmath0 days in the maximum activity period . the results of the analyses of the time series of sunspot area fluctuations from the maximum activity period are contradict with the conclusions of @xcite . she uses the power spectrum analysis only . the periodogram of daily sunspot fluctuations contains peaks , which could be harmonics or subharmonics of the true periodicities . they could be treated as real periodicities . this effect is not visible for sunspot data of the one rotation time interval , but averaging could lose true periodicities . this is observed for data from the southern hemisphere . there is the about @xmath0-day peak in the autocorrelation function of daily fluctuations , but the correlation for data of the one rotation interval is almost zero or negative at the points @xmath164 and 6 rotations . thus , it is reasonable to research both time series together using the correlative and the power spectrum analyses . the following results are obtained :    1 . a new method of the detection of statistically significant peaks of the periodograms enables one to identify aliases in the periodogram . 2 .   two effects cause the existence of the peak of the periodogram of the time series of sunspot area fluctuations at about @xmath0 days : the first is caused by the 27-day periodicity , which probably creates the 162-day periodicity ( it is a subharmonic frequency of the 27-day periodicity ) and the second is caused by statistically significant positive values of the autocorrelation function from the intervals of @xmath165 $ ] and @xmath166 $ ] days . the existence of the periodicity of about @xmath0 days of the time series of sunspot area fluctuations and sunspot area fluctuations from the northern hemisphere during the maximum activity period is questionable . the autocorrelation analysis of the time series of sunspot area fluctuations from the southern hemisphere indicates that the periodicity of about 155 days exists during the maximum activity period . i appreciate valuable comments from professor j. jakimiec .</s>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/Diplom/Pretraining/target.txt\") as infile:\n",
        "    for line in infile:\n",
        "        print(line)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8eVtP_KwGqP"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTejjJkLwF9U"
      },
      "outputs": [],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vx5S2xW5wGDS"
      },
      "outputs": [],
      "source": [
        "masked_file = \"/content/drive/MyDrive/Diplom/Pretraining/masked.txt\"\n",
        "target_file = \"/content/drive/MyDrive/Diplom/Pretraining/target.txt\"\n",
        "tokenized_file = \"/content/drive/MyDrive/Diplom/Pretraining/tokenized_items.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwWJFSta2yVq"
      },
      "outputs": [],
      "source": [
        "with open(target_file) as f:\n",
        "      for len, _ in enumerate(f):\n",
        "          pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1zRmpyLwGGn",
        "outputId": "dbe1c4f5-36ea-49fd-d930-a44525b642c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 215912/215912 [5:20:46<00:00, 11.22it/s]\n"
          ]
        }
      ],
      "source": [
        "with jsonlines.open(tokenized_file, mode='w') as writer:\n",
        "  for idx in tqdm(range(len)):\n",
        "      item = {}\n",
        "      masked_data = getline(masked_file, idx)\n",
        "      target_data = getline(target_file, idx)\n",
        "\n",
        "      tokenized = tokenizer(masked_data, truncation=True, padding=True)\n",
        "      item['input_ids'], item['attention_mask'] = tokenized['input_ids'], tokenized['attention_mask'] \n",
        "      item['labels'] = tokenizer(target_data, truncation=True, padding=True)['input_ids']\n",
        "\n",
        "      writer.write(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0loGPq7kxXdT"
      },
      "source": [
        "# Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjWghHhthTIn"
      },
      "outputs": [],
      "source": [
        "class Arxiv_dataset(Dataset):\n",
        "    #articles might be too long and geting truncated?\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        self.data = []\n",
        "        with jsonlines.open(filename) as reader:\n",
        "            for obj in tqdm(reader):\n",
        "              self.data.append(obj)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx): #проверь, перепутать мог\n",
        "      \n",
        "      item = self.data[idx]     \n",
        "\n",
        "      item['input_ids'] = torch.tensor(item['input_ids'])\n",
        "      item['attention_mask'] = torch.tensor(item['attention_mask'])\n",
        "      item['labels'] = torch.tensor(item['labels'])\n",
        "\n",
        "      return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TftRHbRshTLx",
        "outputId": "c32699ef-f47d-4865-ac98-97be5cb72bfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "215912it [01:25, 2535.54it/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = Arxiv_dataset(\"/content/drive/MyDrive/Diplom/Pretraining/tokenized_items.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcgQgv4vQ32t",
        "outputId": "b890aa10-4d30-45b3-e997-568241e66b2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "215912"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khl9wU0YYHim"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96xsPUVBvRRm"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyTTeww6va0r"
      },
      "outputs": [],
      "source": [
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8HV5IC8vnQ-",
        "outputId": "35699a8e-cb8c-4744-bfa3-d481a49c59fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgm7WTRQP1x3"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILfzoyRrUens"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdy9c0M3RlwW"
      },
      "outputs": [],
      "source": [
        "#total 215912 steps per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbRW1eUcYHlr",
        "outputId": "e4c63def-78fb-4de5-bd11-c9fb538eb142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-11 14:05:56.236256 || Epoch #0, step 0 loss:1.2685335874557495\n",
            "2022-05-11 14:07:01.247989 || Epoch #0, step 100 loss:0.9708780646324158\n",
            "2022-05-11 14:08:05.924340 || Epoch #0, step 200 loss:2.1814215183258057\n",
            "2022-05-11 14:09:10.599435 || Epoch #0, step 300 loss:0.9246693849563599\n",
            "2022-05-11 14:10:15.642054 || Epoch #0, step 400 loss:0.6126791834831238\n",
            "2022-05-11 14:11:20.749378 || Epoch #0, step 500 loss:0.733305037021637\n",
            "2022-05-11 14:12:26.280023 || Epoch #0, step 600 loss:0.4132881462574005\n",
            "2022-05-11 14:13:31.675842 || Epoch #0, step 700 loss:0.7890387773513794\n",
            "2022-05-11 14:14:37.210273 || Epoch #0, step 800 loss:0.6002416014671326\n",
            "2022-05-11 14:15:42.326324 || Epoch #0, step 900 loss:0.7281654477119446\n",
            "2022-05-11 14:16:47.637583 || Epoch #0, step 1000 loss:0.5212292075157166\n",
            "2022-05-11 14:17:52.529452 || Epoch #0, step 1100 loss:0.6972353458404541\n",
            "2022-05-11 14:18:58.060078 || Epoch #0, step 1200 loss:0.9712578654289246\n",
            "2022-05-11 14:20:03.112727 || Epoch #0, step 1300 loss:1.0805423259735107\n",
            "2022-05-11 14:21:07.004726 || Epoch #0, step 1400 loss:0.720300555229187\n",
            "2022-05-11 14:22:11.604139 || Epoch #0, step 1500 loss:0.8371878862380981\n",
            "2022-05-11 14:23:17.105656 || Epoch #0, step 1600 loss:0.6899908781051636\n",
            "2022-05-11 14:24:22.249423 || Epoch #0, step 1700 loss:0.7361578345298767\n",
            "2022-05-11 14:25:26.338776 || Epoch #0, step 1800 loss:0.8323920369148254\n",
            "2022-05-11 14:26:31.331369 || Epoch #0, step 1900 loss:0.5750956535339355\n",
            "2022-05-11 14:27:35.777692 || Epoch #0, step 2000 loss:0.722806453704834\n",
            "2022-05-11 14:28:40.711975 || Epoch #0, step 2100 loss:0.6114744544029236\n",
            "2022-05-11 14:29:46.212360 || Epoch #0, step 2200 loss:0.56365966796875\n",
            "2022-05-11 14:30:51.114905 || Epoch #0, step 2300 loss:0.5627461075782776\n",
            "2022-05-11 14:31:55.614609 || Epoch #0, step 2400 loss:0.3741828501224518\n",
            "2022-05-11 14:33:00.764903 || Epoch #0, step 2500 loss:0.6338233947753906\n",
            "2022-05-11 14:34:05.318674 || Epoch #0, step 2600 loss:0.45133447647094727\n",
            "2022-05-11 14:35:08.847623 || Epoch #0, step 2700 loss:0.43080347776412964\n",
            "2022-05-11 14:36:13.881907 || Epoch #0, step 2800 loss:0.4989027976989746\n",
            "2022-05-11 14:37:18.931305 || Epoch #0, step 2900 loss:0.7312092185020447\n",
            "2022-05-11 14:38:24.143954 || Epoch #0, step 3000 loss:0.4498167634010315\n",
            "2022-05-11 14:39:28.464543 || Epoch #0, step 3100 loss:0.3620363175868988\n",
            "2022-05-11 14:40:32.953299 || Epoch #0, step 3200 loss:0.379077285528183\n",
            "2022-05-11 14:41:37.788314 || Epoch #0, step 3300 loss:0.26363271474838257\n",
            "2022-05-11 14:42:42.805862 || Epoch #0, step 3400 loss:0.29511213302612305\n",
            "2022-05-11 14:43:51.317735 || Epoch #0, step 3500 loss:0.4416015148162842\n",
            "2022-05-11 14:44:56.383326 || Epoch #0, step 3600 loss:0.32636892795562744\n",
            "2022-05-11 14:46:01.615007 || Epoch #0, step 3700 loss:0.26966243982315063\n",
            "2022-05-11 14:47:06.803050 || Epoch #0, step 3800 loss:0.41206464171409607\n",
            "2022-05-11 14:48:11.884389 || Epoch #0, step 3900 loss:0.4211375415325165\n",
            "2022-05-11 14:49:16.321427 || Epoch #0, step 4000 loss:0.45603612065315247\n",
            "2022-05-11 14:50:21.809245 || Epoch #0, step 4100 loss:0.27332210540771484\n",
            "2022-05-11 14:51:26.017738 || Epoch #0, step 4200 loss:0.1606256067752838\n",
            "2022-05-11 14:52:30.993773 || Epoch #0, step 4300 loss:0.19919171929359436\n",
            "2022-05-11 14:53:36.169596 || Epoch #0, step 4400 loss:0.2046227753162384\n",
            "2022-05-11 14:54:40.734859 || Epoch #0, step 4500 loss:0.09416123479604721\n",
            "2022-05-11 14:55:45.556133 || Epoch #0, step 4600 loss:0.3461664617061615\n",
            "2022-05-11 14:56:49.915940 || Epoch #0, step 4700 loss:0.3757340908050537\n",
            "2022-05-11 14:57:53.976700 || Epoch #0, step 4800 loss:0.3177056908607483\n",
            "2022-05-11 14:58:58.974234 || Epoch #0, step 4900 loss:0.39742985367774963\n",
            "2022-05-11 15:00:03.816630 || Epoch #0, step 5000 loss:0.39281368255615234\n",
            "2022-05-11 15:01:09.162472 || Epoch #0, step 5100 loss:0.4162396490573883\n",
            "2022-05-11 15:02:14.464523 || Epoch #0, step 5200 loss:0.5057092905044556\n",
            "2022-05-11 15:03:19.814011 || Epoch #0, step 5300 loss:0.3385860025882721\n",
            "2022-05-11 15:04:24.538929 || Epoch #0, step 5400 loss:0.17812508344650269\n",
            "2022-05-11 15:05:30.014699 || Epoch #0, step 5500 loss:0.3931390047073364\n",
            "2022-05-11 15:06:34.251824 || Epoch #0, step 5600 loss:0.309741348028183\n",
            "2022-05-11 15:07:38.446100 || Epoch #0, step 5700 loss:0.26787981390953064\n",
            "2022-05-11 15:08:43.472601 || Epoch #0, step 5800 loss:0.3821720778942108\n",
            "2022-05-11 15:09:48.176089 || Epoch #0, step 5900 loss:0.38645756244659424\n",
            "2022-05-11 15:10:52.965732 || Epoch #0, step 6000 loss:0.5040059089660645\n",
            "2022-05-11 15:11:58.472110 || Epoch #0, step 6100 loss:0.6880409717559814\n",
            "2022-05-11 15:13:03.691775 || Epoch #0, step 6200 loss:0.4532100558280945\n",
            "2022-05-11 15:14:08.983180 || Epoch #0, step 6300 loss:0.5137406587600708\n",
            "2022-05-11 15:15:14.463401 || Epoch #0, step 6400 loss:0.3888944387435913\n",
            "2022-05-11 15:16:19.467826 || Epoch #0, step 6500 loss:0.6225959062576294\n",
            "2022-05-11 15:17:24.956857 || Epoch #0, step 6600 loss:0.43210628628730774\n",
            "2022-05-11 15:18:29.383079 || Epoch #0, step 6700 loss:0.2314968854188919\n",
            "2022-05-11 15:19:34.490828 || Epoch #0, step 6800 loss:0.337849885225296\n",
            "2022-05-11 15:20:39.294055 || Epoch #0, step 6900 loss:0.39307740330696106\n",
            "2022-05-11 15:21:48.241403 || Epoch #0, step 7000 loss:0.2329142987728119\n",
            "2022-05-11 15:22:52.828026 || Epoch #0, step 7100 loss:0.4104355573654175\n",
            "2022-05-11 15:23:57.630797 || Epoch #0, step 7200 loss:0.2969038486480713\n",
            "2022-05-11 15:25:02.712618 || Epoch #0, step 7300 loss:0.19529977440834045\n",
            "2022-05-11 15:26:08.054181 || Epoch #0, step 7400 loss:0.40221771597862244\n",
            "2022-05-11 15:27:11.377145 || Epoch #0, step 7500 loss:0.1840980350971222\n",
            "2022-05-11 15:28:15.103432 || Epoch #0, step 7600 loss:0.259860098361969\n",
            "2022-05-11 15:29:20.034058 || Epoch #0, step 7700 loss:0.10189589112997055\n",
            "2022-05-11 15:30:24.863751 || Epoch #0, step 7800 loss:0.18827198445796967\n",
            "2022-05-11 15:31:30.378398 || Epoch #0, step 7900 loss:0.32646963000297546\n",
            "2022-05-11 15:32:35.876748 || Epoch #0, step 8000 loss:0.163126140832901\n",
            "2022-05-11 15:33:41.388649 || Epoch #0, step 8100 loss:0.19102002680301666\n",
            "2022-05-11 15:34:46.503821 || Epoch #0, step 8200 loss:0.4679866135120392\n",
            "2022-05-11 15:35:51.769668 || Epoch #0, step 8300 loss:0.39481791853904724\n",
            "2022-05-11 15:36:55.438767 || Epoch #0, step 8400 loss:0.15971870720386505\n",
            "2022-05-11 15:38:00.926363 || Epoch #0, step 8500 loss:0.22922973334789276\n",
            "2022-05-11 15:39:05.168117 || Epoch #0, step 8600 loss:0.18444229662418365\n",
            "2022-05-11 15:40:10.155766 || Epoch #0, step 8700 loss:0.2894517779350281\n",
            "2022-05-11 15:41:15.307797 || Epoch #0, step 8800 loss:0.2862023711204529\n",
            "2022-05-11 15:42:19.635500 || Epoch #0, step 8900 loss:0.3408846855163574\n",
            "2022-05-11 15:43:25.123541 || Epoch #0, step 9000 loss:0.2052304446697235\n",
            "2022-05-11 15:44:30.120392 || Epoch #0, step 9100 loss:0.1787370890378952\n",
            "2022-05-11 15:45:34.776856 || Epoch #0, step 9200 loss:0.31443917751312256\n",
            "2022-05-11 15:46:38.234335 || Epoch #0, step 9300 loss:0.318377822637558\n",
            "2022-05-11 15:47:43.358359 || Epoch #0, step 9400 loss:0.19290731847286224\n",
            "2022-05-11 15:48:48.855184 || Epoch #0, step 9500 loss:0.36423322558403015\n",
            "2022-05-11 15:49:53.939738 || Epoch #0, step 9600 loss:0.21446576714515686\n",
            "2022-05-11 15:50:59.155491 || Epoch #0, step 9700 loss:0.247310072183609\n",
            "2022-05-11 15:52:03.603129 || Epoch #0, step 9800 loss:0.3042951226234436\n",
            "2022-05-11 15:53:08.620006 || Epoch #0, step 9900 loss:0.371980220079422\n",
            "### Scheduler step ### \n",
            "\n",
            "2022-05-11 15:54:12.863890 || Epoch #0, step 10000 loss:0.24534232914447784\n",
            "2022-05-11 15:55:18.362831 || Epoch #0, step 10100 loss:0.19774310290813446\n",
            "2022-05-11 15:56:23.126532 || Epoch #0, step 10200 loss:0.24435710906982422\n",
            "2022-05-11 15:57:28.624035 || Epoch #0, step 10300 loss:0.29235395789146423\n",
            "2022-05-11 15:58:33.906501 || Epoch #0, step 10400 loss:0.08816847950220108\n",
            "2022-05-11 15:59:42.115591 || Epoch #0, step 10500 loss:0.144457146525383\n",
            "2022-05-11 16:00:46.251585 || Epoch #0, step 10600 loss:0.1436462253332138\n",
            "2022-05-11 16:01:51.251863 || Epoch #0, step 10700 loss:0.268555223941803\n",
            "2022-05-11 16:02:56.285944 || Epoch #0, step 10800 loss:0.2671835124492645\n",
            "2022-05-11 16:04:01.628882 || Epoch #0, step 10900 loss:0.29547277092933655\n",
            "2022-05-11 16:05:06.804978 || Epoch #0, step 11000 loss:0.2041366696357727\n",
            "2022-05-11 16:06:10.580213 || Epoch #0, step 11100 loss:0.23790711164474487\n",
            "2022-05-11 16:07:15.504630 || Epoch #0, step 11200 loss:0.3095417618751526\n",
            "2022-05-11 16:08:20.158009 || Epoch #0, step 11300 loss:0.3580605983734131\n",
            "2022-05-11 16:09:25.651486 || Epoch #0, step 11400 loss:0.21012946963310242\n",
            "2022-05-11 16:10:30.955058 || Epoch #0, step 11500 loss:0.46610814332962036\n",
            "2022-05-11 16:11:36.107377 || Epoch #0, step 11600 loss:0.10643947124481201\n",
            "2022-05-11 16:12:40.633469 || Epoch #0, step 11700 loss:0.32009410858154297\n",
            "2022-05-11 16:13:46.112661 || Epoch #0, step 11800 loss:0.16176815330982208\n",
            "2022-05-11 16:14:51.130882 || Epoch #0, step 11900 loss:0.15466701984405518\n",
            "2022-05-11 16:15:56.341435 || Epoch #0, step 12000 loss:0.2828591465950012\n",
            "2022-05-11 16:17:01.840739 || Epoch #0, step 12100 loss:0.292044997215271\n",
            "2022-05-11 16:18:07.340558 || Epoch #0, step 12200 loss:0.11929619312286377\n",
            "2022-05-11 16:19:12.851892 || Epoch #0, step 12300 loss:0.33443158864974976\n",
            "2022-05-11 16:20:18.180397 || Epoch #0, step 12400 loss:0.2581299841403961\n",
            "2022-05-11 16:21:22.752998 || Epoch #0, step 12500 loss:0.20747265219688416\n",
            "2022-05-11 16:22:27.884085 || Epoch #0, step 12600 loss:0.21909622848033905\n",
            "2022-05-11 16:23:33.180403 || Epoch #0, step 12700 loss:0.32390299439430237\n",
            "2022-05-11 16:24:38.674918 || Epoch #0, step 12800 loss:0.17063598334789276\n",
            "2022-05-11 16:25:44.167083 || Epoch #0, step 12900 loss:0.2731461524963379\n",
            "2022-05-11 16:26:48.391377 || Epoch #0, step 13000 loss:0.09627269953489304\n",
            "2022-05-11 16:27:53.502496 || Epoch #0, step 13100 loss:0.5307533144950867\n",
            "2022-05-11 16:28:59.010741 || Epoch #0, step 13200 loss:0.408229798078537\n",
            "2022-05-11 16:30:03.589049 || Epoch #0, step 13300 loss:0.22712133824825287\n",
            "2022-05-11 16:31:09.081466 || Epoch #0, step 13400 loss:0.15074488520622253\n",
            "2022-05-11 16:32:13.453877 || Epoch #0, step 13500 loss:0.27897951006889343\n",
            "2022-05-11 16:33:18.451541 || Epoch #0, step 13600 loss:0.3286040127277374\n",
            "2022-05-11 16:34:22.596482 || Epoch #0, step 13700 loss:0.18199191987514496\n",
            "2022-05-11 16:35:27.776988 || Epoch #0, step 13800 loss:0.20595955848693848\n",
            "2022-05-11 16:36:32.713805 || Epoch #0, step 13900 loss:0.2608891725540161\n",
            "2022-05-11 16:37:42.036491 || Epoch #0, step 14000 loss:0.2591518461704254\n",
            "2022-05-11 16:38:47.546878 || Epoch #0, step 14100 loss:0.21464334428310394\n",
            "2022-05-11 16:39:52.616566 || Epoch #0, step 14200 loss:0.21532544493675232\n",
            "2022-05-11 16:40:57.254937 || Epoch #0, step 14300 loss:0.3162468373775482\n",
            "2022-05-11 16:42:01.956276 || Epoch #0, step 14400 loss:0.09171699732542038\n",
            "2022-05-11 16:43:06.968140 || Epoch #0, step 14500 loss:0.19863276183605194\n",
            "2022-05-11 16:44:11.875373 || Epoch #0, step 14600 loss:0.32896068692207336\n",
            "2022-05-11 16:45:16.378709 || Epoch #0, step 14700 loss:0.30304062366485596\n",
            "2022-05-11 16:46:21.177713 || Epoch #0, step 14800 loss:0.12550188601016998\n",
            "2022-05-11 16:47:26.155508 || Epoch #0, step 14900 loss:0.30008482933044434\n",
            "2022-05-11 16:48:31.165464 || Epoch #0, step 15000 loss:0.3558128774166107\n",
            "2022-05-11 16:49:35.630308 || Epoch #0, step 15100 loss:0.3033931255340576\n",
            "2022-05-11 16:50:40.693305 || Epoch #0, step 15200 loss:0.2866881787776947\n",
            "2022-05-11 16:51:45.666026 || Epoch #0, step 15300 loss:0.40074217319488525\n",
            "2022-05-11 16:52:50.806145 || Epoch #0, step 15400 loss:0.15902872383594513\n",
            "2022-05-11 16:53:55.771579 || Epoch #0, step 15500 loss:0.14340683817863464\n",
            "2022-05-11 16:55:00.285761 || Epoch #0, step 15600 loss:0.2818347215652466\n",
            "2022-05-11 16:56:04.689251 || Epoch #0, step 15700 loss:0.1885792762041092\n",
            "2022-05-11 16:57:09.657702 || Epoch #0, step 15800 loss:0.11542702466249466\n",
            "2022-05-11 16:58:13.545298 || Epoch #0, step 15900 loss:0.18411970138549805\n",
            "2022-05-11 16:59:18.352687 || Epoch #0, step 16000 loss:0.24279174208641052\n",
            "2022-05-11 17:00:23.619776 || Epoch #0, step 16100 loss:0.13810917735099792\n",
            "2022-05-11 17:01:28.677520 || Epoch #0, step 16200 loss:0.2521871328353882\n",
            "2022-05-11 17:02:33.241125 || Epoch #0, step 16300 loss:0.1786036193370819\n",
            "2022-05-11 17:03:38.263974 || Epoch #0, step 16400 loss:0.44847193360328674\n",
            "2022-05-11 17:04:43.581711 || Epoch #0, step 16500 loss:0.20971564948558807\n",
            "2022-05-11 17:05:49.072743 || Epoch #0, step 16600 loss:0.1622765064239502\n",
            "2022-05-11 17:06:53.699259 || Epoch #0, step 16700 loss:0.1355457752943039\n",
            "2022-05-11 17:07:58.314872 || Epoch #0, step 16800 loss:0.054249994456768036\n",
            "2022-05-11 17:09:03.212907 || Epoch #0, step 16900 loss:0.14443637430667877\n",
            "2022-05-11 17:10:08.181041 || Epoch #0, step 17000 loss:0.22233669459819794\n",
            "2022-05-11 17:11:13.508082 || Epoch #0, step 17100 loss:0.28051838278770447\n",
            "2022-05-11 17:12:18.450272 || Epoch #0, step 17200 loss:0.13864019513130188\n",
            "2022-05-11 17:13:23.946901 || Epoch #0, step 17300 loss:0.19972187280654907\n",
            "2022-05-11 17:14:29.434011 || Epoch #0, step 17400 loss:0.16930769383907318\n",
            "2022-05-11 17:15:38.595930 || Epoch #0, step 17500 loss:0.21139474213123322\n",
            "2022-05-11 17:16:43.605316 || Epoch #0, step 17600 loss:0.12189298123121262\n",
            "2022-05-11 17:17:48.587469 || Epoch #0, step 17700 loss:0.29944726824760437\n",
            "2022-05-11 17:18:54.080474 || Epoch #0, step 17800 loss:0.3069995939731598\n",
            "2022-05-11 17:19:58.645142 || Epoch #0, step 17900 loss:0.3063890337944031\n",
            "2022-05-11 17:21:04.129833 || Epoch #0, step 18000 loss:0.16567541658878326\n",
            "2022-05-11 17:22:09.628165 || Epoch #0, step 18100 loss:0.25476792454719543\n",
            "2022-05-11 17:23:15.029624 || Epoch #0, step 18200 loss:0.24654993414878845\n",
            "2022-05-11 17:24:20.302099 || Epoch #0, step 18300 loss:0.2214260846376419\n",
            "2022-05-11 17:25:25.155857 || Epoch #0, step 18400 loss:0.31207385659217834\n",
            "2022-05-11 17:26:30.238893 || Epoch #0, step 18500 loss:0.24994993209838867\n",
            "2022-05-11 17:27:34.979410 || Epoch #0, step 18600 loss:0.2779821753501892\n",
            "2022-05-11 17:28:38.908845 || Epoch #0, step 18700 loss:0.05319322273135185\n",
            "2022-05-11 17:29:44.266589 || Epoch #0, step 18800 loss:0.17199671268463135\n",
            "2022-05-11 17:30:49.337372 || Epoch #0, step 18900 loss:0.18580226600170135\n",
            "2022-05-11 17:31:54.843881 || Epoch #0, step 19000 loss:0.2626139223575592\n"
          ]
        }
      ],
      "source": [
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = lr_scheduler.StepLR(optim, step_size=1, gamma=0.5)\n",
        "loss_history = []\n",
        "i = 0\n",
        "for epoch in range(1):\n",
        "    for batch in dataloader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device) \n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        if len(loss_history) % 100 == 0: #logging\n",
        "          print(f\"{datetime.now()} || Epoch #{epoch}, step {len(loss_history) - (dataset.__len__() * epoch)} loss:{float(loss)}\")\n",
        "\n",
        "        loss_history.append(float(loss))\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        if len(loss_history) % 10000 == 0 and i>0: #LR scheduling\n",
        "          print(\"### Scheduler step ### \\n\")\n",
        "          scheduler.step()\n",
        "        \n",
        "        if len(loss_history) % 3500 == 0:\n",
        "          Path(f\"/content/drive/MyDrive/Diplom/Pretraining/save_{i}\").mkdir(exist_ok=True) #saving\n",
        "          model.save_pretrained(f\"/content/drive/MyDrive/Diplom/Pretraining/save_{i}\")\n",
        "          i+=1\n",
        "\n",
        "model.eval()\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Diplom/Pretraining\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx-azeVZvEDN"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/Diplom/Pretraining\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE2iYF2boEVB"
      },
      "source": [
        "# Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drr0i2_FgFTk"
      },
      "source": [
        "exctractive summary, training and dataset similar to pretraining (pre0tokenization?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtbReUxDoNxM"
      },
      "source": [
        "https://github.com/huggingface/notebooks/blob/main/examples/summarization.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycD1HCa7YHrX"
      },
      "outputs": [],
      "source": [
        "class Arxiv_summarization_dataset(Dataset): #maximum sequence length for this model (18038 > 1024)!\n",
        "    #articles might be too long and geting truncated?\n",
        "\n",
        "    def __init__(self, filename, NER_model_path = \"/content/drive/MyDrive/Diplom/NER/outputs/checkpoint-1372-epoch-7\"):\n",
        "        self.filename = filename\n",
        "        self.tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\") #переименовать чтоб не путать?\n",
        "\n",
        "    def __len__(self): #keep all the file in the ram\n",
        "      with open(self.filename) as f:\n",
        "            for i, _ in enumerate(f, 1):\n",
        "                pass\n",
        "      return i\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx): #Add exctractive summary prior. generate dataset separetely?\n",
        "      item = {}\n",
        "\n",
        "      with open(self.filename) as f:\n",
        "          for i, line in enumerate(f):\n",
        "              if i == idx:\n",
        "                data = json.loads(line)\n",
        "                break\n",
        "      article_text = data['article_text']\n",
        "      article_text = ' '.join(article_text)\n",
        "\n",
        "      abstract_text = ' '.join(data['abstract_text']).replace(\"<S>\", '').replace(\"</S>\", '')\n",
        "\n",
        "      item['input_ids'] = torch.tensor(self.tokenizer(article_text, truncation=True, padding=True)['input_ids'])\n",
        "      item['labels'] = torch.tensor(self.tokenizer(abstract_text, truncation=True, padding=True)['input_ids'])\n",
        "\n",
        "      return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk7R5DEqYHuR"
      },
      "outputs": [],
      "source": [
        "summarization_dataset = Arxiv_summarization_dataset(\"/content/arxiv-dataset/test.txt\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPb6YWbBYHxK"
      },
      "outputs": [],
      "source": [
        "summarization_dataloader = DataLoader(summarization_dataset, batch_size=1, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnaIDaUdYH6Q"
      },
      "outputs": [],
      "source": [
        "summarization_model = BartForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Diplom/Summarization/pretrained_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hUdVW9XxFch"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htg5nkCIxCFJ",
        "outputId": "354ff7f1-97c0-4e5b-c650-017da4879868"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarization_model.to(device)\n",
        "summarization_model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lf_zh3UbYH9I",
        "outputId": "052dc249-dcb3-4d6e-c7e4-b15b83f19846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "tensor(6.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.2578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.7286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.8038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.2801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4.8548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.5488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.7442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.9251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(8.2501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.7031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.1947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.4277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.8321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.2203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.1965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.6441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.6849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.1179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.8421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.5911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.7110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.4692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2cc27cbd273d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummarization_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6f10793a6587>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optim = AdamW(summarization_model.parameters(), lr=5e-5) #ADD scheduler\n",
        "\n",
        "for epoch in range(3):\n",
        "    for batch in summarization_dataloader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = summarization_model(input_ids, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "summarization_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjJZUu4dAqrk",
        "outputId": "a6be49bd-e9e4-4275-dbad-82b6347f1aba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarization_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "uPNvhWNCYIC6",
        "outputId": "10655822-3ddd-4c8e-e1a8-f934c9d956f8"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-87e880ac510f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummarization_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msummarization_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgenerated_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarization_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgenerated_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdecoded_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarization_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1261\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             )\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m             )\n\u001b[1;32m   1644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         )\n\u001b[1;32m   1365\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m         )\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m                 )\n\u001b[1;32m   1106\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "res = []\n",
        "for batch in summarization_dataloader:\n",
        "    summarization_model.to('cpu')\n",
        "    generated_tokens = summarization_model.generate(batch['input_ids'])\n",
        "    generated_tokens = generated_tokens.cpu().numpy()\n",
        "    decoded_preds = summarization_dataset.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "    res.append(decoded_preds)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBv70b20YIFp",
        "outputId": "d5e15d36-2c1c-4a20-f929-dffa45f70e8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[' we we we we we we we we we we we we we we we we we we'],\n",
              " [' we we we we we we we we we we we we we we we we we we'],\n",
              " [' we we we we we we we we we we we we we we we we we we'],\n",
              " [' we we we we we we we we we we we we we we we we we we'],\n",
              " [' we we we we we we we we we we we we we we we we we we'],\n",
              " [' we we we we we we we we we we we we we we we we we we'],\n",
              " [' we we we we we we we we we we we we we we we we we we']]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB3VVo1yYIIo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aehVIyKXnIkk"
      },
      "source": [
        "# Custom metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1RyqlPWYILb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seGYjuP-YIOQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDu-35-JjJob"
      },
      "source": [
        "# Dataset generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCt3s1SsjTyy",
        "outputId": "fe937875-a062-4d97-c9ee-d6caeb6271cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 62.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=4476d2a7e22f8606f79360c4e81ea5a07018dea05dd9c0f708b942d7c48064f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLS-3uTujJod"
      },
      "source": [
        "## NER model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C21UkdU6jJof"
      },
      "outputs": [],
      "source": [
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIHPjA-TjJog"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"/content/drive/MyDrive/Diplom/NER/outputs/checkpoint-1372-epoch-7\")\n",
        "\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g16rhxhXjJoi"
      },
      "outputs": [],
      "source": [
        "def generate_decoder_input(example):\n",
        "    output = copy.deepcopy(example)\n",
        "    \n",
        "    for i in range(len(output)):\n",
        "        output[i] = \"<s>\" + output[i]\n",
        "    \n",
        "    return output\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMY0qbGjJoj"
      },
      "outputs": [],
      "source": [
        "def generate_input(example): #пока не обрабатываю слова составные из двух и более токенов и не маскирую их корректно\n",
        "    ner_results = nlp(example)\n",
        "    output = []\n",
        "    \n",
        "    for i in range(len(ner_results)):\n",
        "      ents = [x['word'] for x in ner_results[i] if x['entity'] != 'LABEL_0' and len(x[\"word\"]) > 3]\n",
        "      words = [x if not [True for y in ents if x.count(y.replace(\"Ġ\", '')) > 0 ] else \"<mask>\" for x in example[0].split()]\n",
        "      output.append(\" \".join(words))\n",
        " \n",
        "    \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrVnWNhVjJok"
      },
      "outputs": [],
      "source": [
        "def generate_labels(example):\n",
        "    output = copy.deepcopy(example)\n",
        "    for i in range(len(output)):\n",
        "        output[i]+=\"</s>\"\n",
        "    \n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twPFFmrBjJoo"
      },
      "source": [
        "# Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE1fOimJ0G7N",
        "outputId": "5df52509-39d4-4687-98f3-2384edc443a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-06 13:19:11--  https://archive.org/download/armancohan-long-summarization-paper-code/pubmed-dataset.zip\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia802905.us.archive.org/4/items/armancohan-long-summarization-paper-code/pubmed-dataset.zip [following]\n",
            "--2022-05-06 13:19:12--  https://ia802905.us.archive.org/4/items/armancohan-long-summarization-paper-code/pubmed-dataset.zip\n",
            "Resolving ia802905.us.archive.org (ia802905.us.archive.org)... 207.241.233.55\n",
            "Connecting to ia802905.us.archive.org (ia802905.us.archive.org)|207.241.233.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 880225504 (839M) [application/zip]\n",
            "Saving to: ‘pubmed-dataset.zip.1’\n",
            "\n",
            "pubmed-dataset.zip.   0%[                    ]       0  --.-KB/s               ^C\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.org/download/armancohan-long-summarization-paper-code/pubmed-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tQ-PkGZ90EA"
      },
      "outputs": [],
      "source": [
        "!cp /content/pubmed-dataset.zip /content/drive/MyDrive/Diplom/Summarization/pubmed-dataset.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo1tddaLjJoq"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-wDDSTZ6UME",
        "outputId": "f7f648a6-f577-44a0-fa1b-c0e8dd438915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Diplom/Summarization/pubmed-dataset.zip\n",
            "   creating: pubmed-dataset/\n",
            "  inflating: __MACOSX/._pubmed-dataset  \n",
            "  inflating: pubmed-dataset/train.txt  \n",
            "  inflating: __MACOSX/pubmed-dataset/._train.txt  \n",
            "  inflating: pubmed-dataset/vocab    \n",
            "  inflating: __MACOSX/pubmed-dataset/._vocab  \n",
            "  inflating: pubmed-dataset/test.txt  \n",
            "  inflating: __MACOSX/pubmed-dataset/._test.txt  \n",
            "  inflating: pubmed-dataset/val.txt  \n",
            "  inflating: __MACOSX/pubmed-dataset/._val.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip  /content/drive/MyDrive/Diplom/Summarization/pubmed-dataset.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "qkVX_jmrX8cl",
        "outputId": "9999ba27-4180-48f2-906b-6d542ff0594f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cad31a50edd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/pubmed-dataset/test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pubmed-dataset/test.txt'"
          ]
        }
      ],
      "source": [
        "with open(\"/content/pubmed-dataset/test.txt\") as file:\n",
        "    example = file.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq2mVjLRb_H6",
        "outputId": "e67cd668-b950-4da6-c9f6-469c1081811b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6658"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d0rtSMIjJor"
      },
      "outputs": [],
      "source": [
        "# from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "\n",
        "# tok = BartTokenizer.from_pretrained(\"facebook/bart-large\") #переписать через класс датасет и даталоадер\n",
        "# model = BartForConditionalGeneration(BartConfig())\n",
        "\n",
        "# for i in tqdm(range(15)):\n",
        "#   for iter in range(len(example)):\n",
        "#     batch = [example[iter]]\n",
        "#     input_batch = generate_input(batch)\n",
        "#     decoder_input_batch = generate_decoder_input(batch)\n",
        "#     labels_batch = generate_labels(batch)\n",
        "\n",
        "#     input_batch[0] = input_batch[0][:1024] #bad solution, need to split docs on  words. already did it befpre\n",
        "#     decoder_input_batch[0] = decoder_input_batch[0][:1024]\n",
        "#     labels_batch[0] = labels_batch[0][:1024]\n",
        "\n",
        "#     input_ids = tok.batch_encode_plus(input_batch, add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
        "#     decoder_input_ids = tok.batch_encode_plus(decoder_input_batch, add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
        "#     labels = tok.batch_encode_plus(labels_batch, add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
        "\n",
        "#     try: #also bug to be solved\n",
        "#       loss = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids, labels=labels)[0]\n",
        "      \n",
        "#       print(f\"Epoch {i}, iteration {iter} loss: {loss}\")\n",
        "#     except: \n",
        "#       pass\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00y2_kQ9WLxf"
      },
      "outputs": [],
      "source": [
        "#encoding=utf-8\n",
        "\n",
        "from transformers import (\n",
        "    BartForConditionalGeneration, BartTokenizer, BartForCausalLM,\n",
        "    Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "  )\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "# ## Initiating model and trainer for training\n",
        "from transformers import BartModel, BartConfig\n",
        "from transformers import BartTokenizerFast\n",
        "\n",
        "\n",
        "configuration = BartConfig(\n",
        "    vocab_size=52000,\n",
        "    max_position_embeddings=258,\n",
        "    d_model=256,\n",
        "    encoder_layers=3,\n",
        "    decoder_layers=3,\n",
        "    encoder_attention_heads=4,\n",
        "    decoder_attention_heads=4,\n",
        "    decoder_ffn_dim=1024,\n",
        "    encoder_ffn_dim=1024,\n",
        ")\n",
        "model = BartForCausalLM(configuration)\n",
        "tokenizer = BartTokenizerFast.from_pretrained(\"./dic\", max_len=256, additional_special_tokens=['[CH]', '[OTHER]', '[VAR]', '[NUM]'])\n",
        "\n",
        "\n",
        "# ### HTTP Request DataPreparing & Modeling\n",
        "data = []\n",
        "with open(\"../data/sample.txt\") as f1:\n",
        "    for src in f1:\n",
        "      data.append(\n",
        "          {\n",
        "              \"seq2seq\": {\n",
        "                  \"input\": src.strip()\n",
        "              }\n",
        "          }\n",
        "      )\n",
        "print(f'total size of data is {len(data)}')\n",
        "\n",
        "\n",
        "# splitting dataset into train, validation\n",
        "split = 0.2\n",
        "train_dataset, eval_dataset = random_split(data, lengths=[int((1-split)*len(data))+1, int(split*len(data))])\n",
        "\n",
        "\n",
        "# defining collator functioon for preparing batches on the fly ..\n",
        "def data_collator(features:list):\n",
        "   inputs = [f[\"seq2seq\"][\"input\"] for f in features]\n",
        "   batch = tokenizer.prepare_seq2seq_batch(src_texts=inputs, max_length=256, padding='max_length')\n",
        "   batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
        "   for k in batch:\n",
        "        batch[k] = torch.tensor(batch[k])\n",
        "   return batch\n",
        "\n",
        "\n",
        "batch_out = data_collator(eval_dataset)\n",
        "print(batch_out)\n",
        "print(batch_out['input_ids'].shape,batch_out['labels'].shape,batch_out['attention_mask'].shape)\n",
        "\n",
        "\n",
        "# defining training related arguments\n",
        "args = Seq2SeqTrainingArguments(output_dir=\"clm-checkpoints\",\n",
        "                        do_train=True,\n",
        "                        do_eval=True,\n",
        "                        evaluation_strategy=\"epoch\",\n",
        "                        per_device_train_batch_size=8,\n",
        "                        per_device_eval_batch_size=8,\n",
        "                        learning_rate=5e-5,\n",
        "                        num_train_epochs=1,\n",
        "                        logging_dir=\"./logs\")\n",
        "\n",
        "\n",
        "# defining trainer using 🤗\n",
        "trainer = Seq2SeqTrainer(model=model, \n",
        "                args=args, \n",
        "                data_collator=data_collator, \n",
        "                train_dataset=train_dataset, \n",
        "                eval_dataset=eval_dataset)\n",
        "\n",
        "\n",
        "# ## Training time\n",
        "trainer.train()\n",
        "# It will take hours to train this model on this dataset\n",
        "\n",
        "\n",
        "# lets save model\n",
        "trainer.evaluate(eval_dataset=eval_dataset)\n",
        "trainer.save_model(\"clm-checkpoints\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "ybSf7_rWNv8O",
        "outputId": "c46f2e0d-7328-4c25-c5ea-1951d8c6f612"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3d27167fe07e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'input_ids' is not defined"
          ]
        }
      ],
      "source": [
        "len(input_ids[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhshaU5Eh41o",
        "outputId": "c1e11ec4-f6c9-4d92-bca8-2095b1c46022"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "223"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(decoder_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvGHDav9h9Dh",
        "outputId": "60fb017e-40ff-468a-f46c-7c422129ba21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmWwHHhhjJos"
      },
      "outputs": [],
      "source": [
        "model(input_ids=input_ids.unsqueeze(0), decoder_input_ids=decoder_input_ids.unsqueeze(0), labels=labels.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDsKjlDm1hxH"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/Diplom/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQUT1L8SjJos"
      },
      "source": [
        "### dataset handeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUTm4YUBjJoy"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYQKIPYVjJoy",
        "outputId": "5b53469e-8c47-4a8c-d4bd-620b18aa67e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from transformers import (\n",
        "    BartForConditionalGeneration,\n",
        "    BartTokenizerFast,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    AdamW,\n",
        "    get_scheduler,\n",
        ")\n",
        "\n",
        "from datasets import (\n",
        "    load_metric, \n",
        "    load_dataset,\n",
        "    load_from_disk\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch\n",
        "import nltk\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "nltk.download('punkt');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCxS_ntejJoy"
      },
      "source": [
        "# Preparation of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTm5rr_QjJoy",
        "outputId": "adb6038a-6b3d-4703-e955-e7e4d825cffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\r\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTHuSVhkjJoz"
      },
      "outputs": [],
      "source": [
        "# Dataset parameters\n",
        "\n",
        "batch_size = 2\n",
        "max_source_length = 1024\n",
        "max_target_length = 256\n",
        "padding = 'max_length'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2kYZeFKjJoz"
      },
      "outputs": [],
      "source": [
        "# Loading pretrained facebook/bart-base tokenizer\n",
        "\n",
        "tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgrZeFvZjJo0",
        "outputId": "99cc5004-b00b-4e65-c1a9-88d0312d64c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading raw CNN/DailyMail dataset\n",
        "\n",
        "raw_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
        "column_names = raw_dataset['train'].column_names\n",
        "\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i2FV-64jJo0"
      },
      "outputs": [],
      "source": [
        "# Function for processing dataset for loading into a model\n",
        "\n",
        "def process_data_to_model_inputs(example):\n",
        "    inputs = example['article']\n",
        "    targets = example['highlights']\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)\n",
        "\n",
        "    labels['input_ids'] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels['input_ids']]\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    \n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvrM5ZHujJo1",
        "outputId": "10d70964-fd0d-434d-aba8-acad42182387"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d01f1b3033284967861320017af47c58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4487 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "202c81e71ebd4926abece38dfa65dc08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/209 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6202fe1ecd0412ba1844846578915f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/180 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 287113\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 13368\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 11490\n",
              " }))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Processing dataset, split on train, eval, test datasets\n",
        "\n",
        "dataset = raw_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched = True,\n",
        "    batch_size = batch_size,\n",
        "    remove_columns = column_names,\n",
        "    load_from_cache_file = True,\n",
        ")\n",
        "\n",
        "train_dataset = dataset['train']\n",
        "eval_dataset = dataset['validation']\n",
        "test_dataset = dataset['test']\n",
        "\n",
        "train_dataset, eval_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3Jjo7DTjJo1"
      },
      "outputs": [],
      "source": [
        "# Saving dataset to disk for later reuse\n",
        "\n",
        "dataset.save_to_disk('content/processed_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "817NWdh3jJo2",
        "outputId": "ec75f004-7f50-414b-b8df-41ae02f5f6c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 287113\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 13368\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 11490\n",
              " }))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading dataset from disk for reuse\n",
        "\n",
        "dataset = load_from_disk('content/processed_dataset')\n",
        "\n",
        "train_dataset = dataset['train']\n",
        "eval_dataset = dataset['validation']\n",
        "test_dataset = dataset['test']\n",
        "\n",
        "train_dataset, eval_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lozrRRvajJo2",
        "outputId": "0c50875a-e5b9-4c27-8531-b180d0046fc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 287113\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 13368\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 13368\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['attention_mask', 'input_ids', 'labels'],\n",
              "     num_rows: 11490\n",
              " }))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Taking a part of the dataset for test training\n",
        "\n",
        "dataset_part = 1\n",
        "\n",
        "train_dataset = dataset['train'].select(range(len(dataset['train']) // dataset_part))\n",
        "eval_dataset = dataset['validation'].select(range(len(dataset['validation']) // dataset_part))\n",
        "test_dataset = dataset['test'].select(range(len(dataset['test']) // dataset_part))\n",
        "\n",
        "train_subset = train_dataset.select(range(len(eval_dataset)))\n",
        "\n",
        "train_dataset, train_subset, eval_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6SIhad3jJo2"
      },
      "source": [
        "# Preparation of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsYSTz1OjJo3"
      },
      "outputs": [],
      "source": [
        "# Loading pretrained facebook/bart-base model: BartForConditionalGeneration\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9osdBRhjJo3"
      },
      "outputs": [],
      "source": [
        "# DataLoaders for each dataset\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    padding=padding\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "subset_dataloader = DataLoader(\n",
        "    train_subset,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j71THrRDjJo4"
      },
      "outputs": [],
      "source": [
        "# Function for post-processing generated texts\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nnSClSgjJo4"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpemjV_SjJo4",
        "outputId": "7a7fb9b7-ba05-4f50-a7a9-779abdef8cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Aug 11 17:33:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.152.00   Driver Version: 418.152.00   CUDA Version: 11.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
            "| N/A   52C    P0   237W / 300W |   9959MiB / 32478MiB |     83%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
            "| N/A   47C    P0    53W / 300W |  16326MiB / 32478MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
            "| N/A   47C    P0    51W / 300W |   2733MiB / 32478MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
            "| N/A   47C    P0    50W / 300W |   3007MiB / 32478MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03-hte9fjJo5"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "\n",
        "epoch_num = 10\n",
        "optimizer_steps = 128\n",
        "\n",
        "base_learning_rate = 3e-4\n",
        "betas = (0.9, 0.999)\n",
        "eps = 1e-8\n",
        "weight_decay = 0.01\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay': 0.01,\n",
        "    },\n",
        "    {\n",
        "        'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay': 0.0,\n",
        "    },\n",
        "]\n",
        "\n",
        "num_warmup_steps = 256\n",
        "num_training_steps = epoch_num * len(train_dataloader)\n",
        "lr_scheduler_type = 'linear'\n",
        "\n",
        "num_beams = 3\n",
        "\n",
        "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6ptXl2MjJo5"
      },
      "outputs": [],
      "source": [
        "# Optimizer: AdamW\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=base_learning_rate,\n",
        "    betas=betas,\n",
        "    eps=eps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ4CZgbujJo5"
      },
      "outputs": [],
      "source": [
        "# Lr_scheduler\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=lr_scheduler_type,\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b1n4x9IjJo6"
      },
      "outputs": [],
      "source": [
        "# Metric\n",
        "\n",
        "metric = load_metric('rouge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U37_B3OjJo6",
        "outputId": "4c6449b2-7d1c-4a2f-e2c3-dacd76b292f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transfer model to GPU\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2DQGY3VjJo6"
      },
      "outputs": [],
      "source": [
        "# Metrics\n",
        "\n",
        "train_losses = []\n",
        "train_losses_epoch = []\n",
        "eval_losses_epoch = []\n",
        "metrics = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T-Dtcs2jJo7"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGMt2KmRjJo8",
        "outputId": "0670cb73-343d-4c73-cc0b-1ee454fc97e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model training\n",
            "opimizers updated, step 1 / 1435570, loss 4.326367378234863\n",
            "opimizers updated, step 129 / 1435570, loss 569.5679888725281\n",
            "opimizers updated, step 257 / 1435570, loss 549.0737895965576\n",
            "opimizers updated, step 385 / 1435570, loss 544.4964938163757\n",
            "opimizers updated, step 513 / 1435570, loss 523.524290561676\n",
            "opimizers updated, step 641 / 1435570, loss 516.6678054332733\n",
            "opimizers updated, step 769 / 1435570, loss 504.1267936229706\n",
            "opimizers updated, step 897 / 1435570, loss 480.6759955883026\n",
            "opimizers updated, step 1025 / 1435570, loss 485.59634804725647\n",
            "opimizers updated, step 1153 / 1435570, loss 475.6121323108673\n",
            "opimizers updated, step 1281 / 1435570, loss 458.60372829437256\n",
            "opimizers updated, step 1409 / 1435570, loss 439.793946146965\n",
            "opimizers updated, step 1537 / 1435570, loss 435.33740639686584\n",
            "opimizers updated, step 1665 / 1435570, loss 415.49433290958405\n",
            "opimizers updated, step 1793 / 1435570, loss 418.0387616157532\n",
            "opimizers updated, step 1921 / 1435570, loss 409.5816035270691\n",
            "opimizers updated, step 2049 / 1435570, loss 402.77449882030487\n",
            "opimizers updated, step 2177 / 1435570, loss 394.28254199028015\n",
            "opimizers updated, step 2305 / 1435570, loss 382.7154850959778\n",
            "opimizers updated, step 2433 / 1435570, loss 383.06559443473816\n",
            "opimizers updated, step 2561 / 1435570, loss 381.28036189079285\n",
            "opimizers updated, step 2689 / 1435570, loss 374.9692550897598\n",
            "opimizers updated, step 2817 / 1435570, loss 369.2015906572342\n",
            "opimizers updated, step 2945 / 1435570, loss 366.148334980011\n",
            "opimizers updated, step 3073 / 1435570, loss 365.29709708690643\n",
            "opimizers updated, step 3201 / 1435570, loss 361.7554929256439\n",
            "opimizers updated, step 3329 / 1435570, loss 354.8096423149109\n",
            "opimizers updated, step 3457 / 1435570, loss 346.62967801094055\n",
            "opimizers updated, step 3585 / 1435570, loss 344.09714794158936\n",
            "opimizers updated, step 3713 / 1435570, loss 341.1741998195648\n",
            "opimizers updated, step 3841 / 1435570, loss 344.5966213941574\n",
            "opimizers updated, step 3969 / 1435570, loss 337.69809913635254\n",
            "opimizers updated, step 4097 / 1435570, loss 324.6456105709076\n",
            "opimizers updated, step 4225 / 1435570, loss 328.4112911224365\n",
            "opimizers updated, step 4353 / 1435570, loss 323.3799525499344\n",
            "opimizers updated, step 4481 / 1435570, loss 320.3372970819473\n",
            "opimizers updated, step 4609 / 1435570, loss 312.1018455028534\n",
            "opimizers updated, step 4737 / 1435570, loss 313.83206367492676\n",
            "opimizers updated, step 4865 / 1435570, loss 307.7608366012573\n",
            "opimizers updated, step 4993 / 1435570, loss 312.33379316329956\n",
            "opimizers updated, step 5121 / 1435570, loss 306.6567908525467\n",
            "opimizers updated, step 5249 / 1435570, loss 305.5007652044296\n",
            "opimizers updated, step 5377 / 1435570, loss 306.0333718061447\n",
            "opimizers updated, step 5505 / 1435570, loss 307.75314980745316\n",
            "opimizers updated, step 5633 / 1435570, loss 311.93526470661163\n",
            "opimizers updated, step 5761 / 1435570, loss 314.1278339624405\n",
            "opimizers updated, step 5889 / 1435570, loss 299.9119622707367\n",
            "opimizers updated, step 6017 / 1435570, loss 295.35016322135925\n",
            "opimizers updated, step 6145 / 1435570, loss 309.22283363342285\n",
            "opimizers updated, step 6273 / 1435570, loss 291.74156391620636\n",
            "opimizers updated, step 6401 / 1435570, loss 297.88037288188934\n",
            "opimizers updated, step 6529 / 1435570, loss 296.5477614402771\n",
            "opimizers updated, step 6657 / 1435570, loss 301.73753798007965\n",
            "opimizers updated, step 6785 / 1435570, loss 289.47751331329346\n",
            "opimizers updated, step 6913 / 1435570, loss 290.84101939201355\n",
            "opimizers updated, step 7041 / 1435570, loss 283.33682692050934\n",
            "opimizers updated, step 7169 / 1435570, loss 291.1494415998459\n",
            "opimizers updated, step 7297 / 1435570, loss 292.4667316675186\n",
            "opimizers updated, step 7425 / 1435570, loss 291.8128016591072\n",
            "opimizers updated, step 7553 / 1435570, loss 295.7669414281845\n",
            "opimizers updated, step 7681 / 1435570, loss 296.6636233329773\n",
            "opimizers updated, step 7809 / 1435570, loss 286.4571968317032\n",
            "opimizers updated, step 7937 / 1435570, loss 288.39797496795654\n",
            "opimizers updated, step 8065 / 1435570, loss 285.2521777153015\n",
            "opimizers updated, step 8193 / 1435570, loss 291.64819252491\n",
            "opimizers updated, step 8321 / 1435570, loss 279.3877388238907\n",
            "opimizers updated, step 8449 / 1435570, loss 291.92416524887085\n",
            "opimizers updated, step 8577 / 1435570, loss 285.86917877197266\n",
            "opimizers updated, step 8705 / 1435570, loss 284.08448219299316\n",
            "opimizers updated, step 8833 / 1435570, loss 286.20844197273254\n",
            "opimizers updated, step 8961 / 1435570, loss 287.43746507167816\n",
            "opimizers updated, step 9089 / 1435570, loss 289.6111904978752\n",
            "opimizers updated, step 9217 / 1435570, loss 282.360458612442\n",
            "opimizers updated, step 9345 / 1435570, loss 279.1490846276283\n",
            "opimizers updated, step 9473 / 1435570, loss 274.98708510398865\n",
            "opimizers updated, step 9601 / 1435570, loss 285.6930792927742\n",
            "opimizers updated, step 9729 / 1435570, loss 281.9749504327774\n",
            "opimizers updated, step 9857 / 1435570, loss 285.59990108013153\n",
            "opimizers updated, step 9985 / 1435570, loss 278.23834335803986\n",
            "opimizers updated, step 10113 / 1435570, loss 281.6553391814232\n",
            "opimizers updated, step 10241 / 1435570, loss 272.5545984506607\n",
            "opimizers updated, step 10369 / 1435570, loss 273.30467212200165\n",
            "opimizers updated, step 10497 / 1435570, loss 278.88436257839203\n",
            "opimizers updated, step 10625 / 1435570, loss 271.48959708213806\n",
            "opimizers updated, step 10753 / 1435570, loss 273.3178491592407\n",
            "opimizers updated, step 10881 / 1435570, loss 276.29723358154297\n",
            "opimizers updated, step 11009 / 1435570, loss 282.117222905159\n",
            "opimizers updated, step 11137 / 1435570, loss 276.5081169605255\n",
            "opimizers updated, step 11265 / 1435570, loss 277.3251795768738\n",
            "opimizers updated, step 11393 / 1435570, loss 273.8026188611984\n",
            "opimizers updated, step 11521 / 1435570, loss 280.3969521522522\n",
            "opimizers updated, step 11649 / 1435570, loss 278.3988403081894\n",
            "opimizers updated, step 11777 / 1435570, loss 275.0667984485626\n",
            "opimizers updated, step 11905 / 1435570, loss 278.1309643983841\n",
            "opimizers updated, step 12033 / 1435570, loss 274.6517856121063\n",
            "opimizers updated, step 12161 / 1435570, loss 277.657289147377\n",
            "opimizers updated, step 12289 / 1435570, loss 279.3511257171631\n",
            "opimizers updated, step 12417 / 1435570, loss 266.3984135389328\n",
            "opimizers updated, step 12545 / 1435570, loss 278.77452278137207\n",
            "opimizers updated, step 12673 / 1435570, loss 277.46578073501587\n",
            "opimizers updated, step 12801 / 1435570, loss 271.91301000118256\n",
            "opimizers updated, step 12929 / 1435570, loss 268.3220158815384\n",
            "opimizers updated, step 13057 / 1435570, loss 269.08871126174927\n",
            "opimizers updated, step 13185 / 1435570, loss 273.37593626976013\n",
            "opimizers updated, step 13313 / 1435570, loss 279.0052295923233\n",
            "opimizers updated, step 13441 / 1435570, loss 270.4537513256073\n",
            "opimizers updated, step 13569 / 1435570, loss 269.02358281612396\n",
            "opimizers updated, step 13697 / 1435570, loss 283.810928940773\n",
            "opimizers updated, step 13825 / 1435570, loss 267.2342674732208\n",
            "opimizers updated, step 13953 / 1435570, loss 270.4993063211441\n",
            "opimizers updated, step 14081 / 1435570, loss 271.98450553417206\n",
            "opimizers updated, step 14209 / 1435570, loss 268.65668284893036\n",
            "opimizers updated, step 14337 / 1435570, loss 272.1294726729393\n",
            "opimizers updated, step 14465 / 1435570, loss 268.41493558883667\n",
            "opimizers updated, step 14593 / 1435570, loss 275.2718359231949\n",
            "opimizers updated, step 14721 / 1435570, loss 279.6187205314636\n",
            "opimizers updated, step 14849 / 1435570, loss 277.83994686603546\n",
            "opimizers updated, step 14977 / 1435570, loss 276.19842052459717\n",
            "opimizers updated, step 15105 / 1435570, loss 280.4442957639694\n",
            "opimizers updated, step 15233 / 1435570, loss 277.25852102041245\n",
            "opimizers updated, step 15361 / 1435570, loss 272.9241632223129\n",
            "opimizers updated, step 15489 / 1435570, loss 269.3675866127014\n",
            "opimizers updated, step 15617 / 1435570, loss 279.07800155878067\n",
            "opimizers updated, step 15745 / 1435570, loss 264.411208987236\n",
            "opimizers updated, step 15873 / 1435570, loss 268.20492446422577\n",
            "opimizers updated, step 16001 / 1435570, loss 259.8013073205948\n",
            "opimizers updated, step 16129 / 1435570, loss 266.9639424085617\n",
            "opimizers updated, step 16257 / 1435570, loss 273.72670888900757\n",
            "opimizers updated, step 16385 / 1435570, loss 263.79712158441544\n",
            "opimizers updated, step 16513 / 1435570, loss 278.4903312921524\n",
            "opimizers updated, step 16641 / 1435570, loss 274.15723264217377\n",
            "opimizers updated, step 16769 / 1435570, loss 270.96385180950165\n",
            "opimizers updated, step 16897 / 1435570, loss 265.1583403944969\n",
            "opimizers updated, step 17025 / 1435570, loss 260.9828271865845\n",
            "opimizers updated, step 17153 / 1435570, loss 271.9037901163101\n",
            "opimizers updated, step 17281 / 1435570, loss 263.1230537891388\n",
            "opimizers updated, step 17409 / 1435570, loss 267.4444054365158\n",
            "opimizers updated, step 17537 / 1435570, loss 270.49348390102386\n",
            "opimizers updated, step 17665 / 1435570, loss 271.8874664902687\n",
            "opimizers updated, step 17793 / 1435570, loss 264.01902961730957\n",
            "opimizers updated, step 17921 / 1435570, loss 256.52360355854034\n",
            "opimizers updated, step 18049 / 1435570, loss 264.8892968893051\n",
            "opimizers updated, step 18177 / 1435570, loss 268.9814334511757\n",
            "opimizers updated, step 18305 / 1435570, loss 273.4779897928238\n",
            "opimizers updated, step 18433 / 1435570, loss 273.75459092855453\n",
            "opimizers updated, step 18561 / 1435570, loss 270.1782020330429\n",
            "opimizers updated, step 18689 / 1435570, loss 269.5665875673294\n",
            "opimizers updated, step 18817 / 1435570, loss 262.2938296198845\n",
            "opimizers updated, step 18945 / 1435570, loss 260.79609298706055\n",
            "opimizers updated, step 19073 / 1435570, loss 265.8775347471237\n",
            "opimizers updated, step 19201 / 1435570, loss 267.03168815374374\n",
            "opimizers updated, step 19329 / 1435570, loss 269.5333893299103\n",
            "opimizers updated, step 19457 / 1435570, loss 264.98604357242584\n",
            "opimizers updated, step 19585 / 1435570, loss 265.51015269756317\n",
            "opimizers updated, step 19713 / 1435570, loss 258.0205252766609\n",
            "opimizers updated, step 19841 / 1435570, loss 264.4417269229889\n",
            "opimizers updated, step 19969 / 1435570, loss 269.84090065956116\n",
            "opimizers updated, step 20097 / 1435570, loss 259.09601974487305\n",
            "opimizers updated, step 20225 / 1435570, loss 267.10619980096817\n",
            "opimizers updated, step 20353 / 1435570, loss 269.21073573827744\n",
            "opimizers updated, step 20481 / 1435570, loss 266.48908615112305\n",
            "opimizers updated, step 20609 / 1435570, loss 265.1155401468277\n",
            "opimizers updated, step 20737 / 1435570, loss 268.5742255449295\n",
            "opimizers updated, step 20865 / 1435570, loss 260.4329845905304\n",
            "opimizers updated, step 20993 / 1435570, loss 274.66324758529663\n",
            "opimizers updated, step 21121 / 1435570, loss 263.2803971171379\n",
            "opimizers updated, step 21249 / 1435570, loss 258.45607525110245\n",
            "opimizers updated, step 21377 / 1435570, loss 262.4846382141113\n",
            "opimizers updated, step 21505 / 1435570, loss 263.2520810365677\n",
            "opimizers updated, step 21633 / 1435570, loss 265.4682973623276\n",
            "opimizers updated, step 21761 / 1435570, loss 278.70940136909485\n",
            "opimizers updated, step 21889 / 1435570, loss 264.7512237429619\n",
            "opimizers updated, step 22017 / 1435570, loss 273.5852960348129\n",
            "opimizers updated, step 22145 / 1435570, loss 259.78077644109726\n",
            "opimizers updated, step 22273 / 1435570, loss 261.1329709291458\n",
            "opimizers updated, step 22401 / 1435570, loss 260.6214975118637\n",
            "opimizers updated, step 22529 / 1435570, loss 272.3233829140663\n",
            "opimizers updated, step 22657 / 1435570, loss 268.6576843261719\n",
            "opimizers updated, step 22785 / 1435570, loss 267.49433171749115\n",
            "opimizers updated, step 22913 / 1435570, loss 270.4259001612663\n",
            "opimizers updated, step 23041 / 1435570, loss 265.37167650461197\n",
            "opimizers updated, step 23169 / 1435570, loss 266.85355961322784\n",
            "opimizers updated, step 23297 / 1435570, loss 270.9147902727127\n",
            "opimizers updated, step 23425 / 1435570, loss 263.2362023591995\n",
            "opimizers updated, step 23553 / 1435570, loss 261.7803971171379\n",
            "opimizers updated, step 23681 / 1435570, loss 268.81545251607895\n",
            "opimizers updated, step 23809 / 1435570, loss 261.14219784736633\n",
            "opimizers updated, step 23937 / 1435570, loss 264.7881190776825\n",
            "opimizers updated, step 24065 / 1435570, loss 261.63462722301483\n",
            "opimizers updated, step 24193 / 1435570, loss 257.5208904147148\n",
            "opimizers updated, step 24321 / 1435570, loss 265.9870421886444\n",
            "opimizers updated, step 24449 / 1435570, loss 263.8135786652565\n",
            "opimizers updated, step 24577 / 1435570, loss 266.2687829732895\n",
            "opimizers updated, step 24705 / 1435570, loss 266.31020736694336\n",
            "opimizers updated, step 24833 / 1435570, loss 262.8351023197174\n",
            "opimizers updated, step 24961 / 1435570, loss 254.53785705566406\n",
            "opimizers updated, step 25089 / 1435570, loss 259.99232375621796\n",
            "opimizers updated, step 25217 / 1435570, loss 263.14244174957275\n",
            "opimizers updated, step 25345 / 1435570, loss 264.26933324337006\n",
            "opimizers updated, step 25473 / 1435570, loss 258.38269823789597\n",
            "opimizers updated, step 25601 / 1435570, loss 257.6615751385689\n",
            "opimizers updated, step 25729 / 1435570, loss 257.08611780405045\n",
            "opimizers updated, step 25857 / 1435570, loss 265.16798174381256\n",
            "opimizers updated, step 25985 / 1435570, loss 271.1221204996109\n",
            "opimizers updated, step 26113 / 1435570, loss 256.3155168890953\n",
            "opimizers updated, step 26241 / 1435570, loss 257.1221049427986\n",
            "opimizers updated, step 26369 / 1435570, loss 260.74475145339966\n",
            "opimizers updated, step 26497 / 1435570, loss 266.6319886445999\n",
            "opimizers updated, step 26625 / 1435570, loss 257.9179736375809\n",
            "opimizers updated, step 26753 / 1435570, loss 264.72927820682526\n",
            "opimizers updated, step 26881 / 1435570, loss 267.2779466509819\n",
            "opimizers updated, step 27009 / 1435570, loss 256.0586887001991\n",
            "opimizers updated, step 27137 / 1435570, loss 263.0340619087219\n",
            "opimizers updated, step 27265 / 1435570, loss 265.8581130504608\n",
            "opimizers updated, step 27393 / 1435570, loss 262.7146458029747\n",
            "opimizers updated, step 27521 / 1435570, loss 265.82966470718384\n",
            "opimizers updated, step 27649 / 1435570, loss 265.69279557466507\n",
            "opimizers updated, step 27777 / 1435570, loss 270.3591034412384\n",
            "opimizers updated, step 27905 / 1435570, loss 260.71305364370346\n",
            "opimizers updated, step 28033 / 1435570, loss 266.4807507991791\n",
            "opimizers updated, step 28161 / 1435570, loss 254.43204843997955\n",
            "opimizers updated, step 28289 / 1435570, loss 267.9782834649086\n",
            "opimizers updated, step 28417 / 1435570, loss 263.38523030281067\n",
            "opimizers updated, step 28545 / 1435570, loss 259.15069013834\n",
            "opimizers updated, step 28673 / 1435570, loss 258.8299633860588\n",
            "opimizers updated, step 28801 / 1435570, loss 268.88245099782944\n",
            "opimizers updated, step 28929 / 1435570, loss 249.86157262325287\n",
            "opimizers updated, step 29057 / 1435570, loss 258.42035657167435\n",
            "opimizers updated, step 29185 / 1435570, loss 257.78345692157745\n",
            "opimizers updated, step 29313 / 1435570, loss 253.31941026449203\n",
            "opimizers updated, step 29441 / 1435570, loss 260.4121845960617\n",
            "opimizers updated, step 29569 / 1435570, loss 262.8066640496254\n",
            "opimizers updated, step 29697 / 1435570, loss 258.9941873550415\n",
            "opimizers updated, step 29825 / 1435570, loss 254.86456871032715\n",
            "opimizers updated, step 29953 / 1435570, loss 264.16139125823975\n",
            "opimizers updated, step 30081 / 1435570, loss 260.94493931531906\n",
            "opimizers updated, step 30209 / 1435570, loss 256.4739991426468\n",
            "opimizers updated, step 30337 / 1435570, loss 258.35936683416367\n",
            "opimizers updated, step 30465 / 1435570, loss 258.9985845685005\n",
            "opimizers updated, step 30593 / 1435570, loss 262.4019426703453\n",
            "opimizers updated, step 30721 / 1435570, loss 257.27689957618713\n",
            "opimizers updated, step 30849 / 1435570, loss 259.1557809114456\n",
            "opimizers updated, step 30977 / 1435570, loss 260.03165566921234\n",
            "opimizers updated, step 31105 / 1435570, loss 261.18221390247345\n",
            "opimizers updated, step 31233 / 1435570, loss 257.26780438423157\n",
            "opimizers updated, step 31361 / 1435570, loss 254.8817493915558\n",
            "opimizers updated, step 31489 / 1435570, loss 265.7639437317848\n",
            "opimizers updated, step 31617 / 1435570, loss 260.64542043209076\n",
            "opimizers updated, step 31745 / 1435570, loss 262.7747107744217\n",
            "opimizers updated, step 31873 / 1435570, loss 256.535708129406\n",
            "opimizers updated, step 32001 / 1435570, loss 256.46428084373474\n",
            "opimizers updated, step 32129 / 1435570, loss 248.64147716760635\n",
            "opimizers updated, step 32257 / 1435570, loss 256.55939543247223\n",
            "opimizers updated, step 32385 / 1435570, loss 264.48769295215607\n",
            "opimizers updated, step 32513 / 1435570, loss 260.4186182022095\n",
            "opimizers updated, step 32641 / 1435570, loss 262.51540011167526\n",
            "opimizers updated, step 32769 / 1435570, loss 262.6047749519348\n",
            "opimizers updated, step 32897 / 1435570, loss 268.42781245708466\n",
            "opimizers updated, step 33025 / 1435570, loss 255.0912522673607\n",
            "opimizers updated, step 33153 / 1435570, loss 267.64858400821686\n",
            "opimizers updated, step 33281 / 1435570, loss 264.1428046822548\n",
            "opimizers updated, step 33409 / 1435570, loss 257.0251727104187\n",
            "opimizers updated, step 33537 / 1435570, loss 260.96047163009644\n",
            "opimizers updated, step 33665 / 1435570, loss 256.055932700634\n",
            "opimizers updated, step 33793 / 1435570, loss 267.8254331946373\n",
            "opimizers updated, step 33921 / 1435570, loss 266.05210268497467\n",
            "opimizers updated, step 34049 / 1435570, loss 257.141864836216\n",
            "opimizers updated, step 34177 / 1435570, loss 259.5252503156662\n",
            "opimizers updated, step 34305 / 1435570, loss 260.74191480875015\n",
            "opimizers updated, step 34433 / 1435570, loss 256.70379000902176\n",
            "opimizers updated, step 34561 / 1435570, loss 256.3343105316162\n",
            "opimizers updated, step 34689 / 1435570, loss 260.9824820160866\n",
            "opimizers updated, step 34817 / 1435570, loss 253.99856287240982\n",
            "opimizers updated, step 34945 / 1435570, loss 265.13826179504395\n",
            "opimizers updated, step 35073 / 1435570, loss 254.74554538726807\n",
            "opimizers updated, step 35201 / 1435570, loss 251.21044075489044\n",
            "opimizers updated, step 35329 / 1435570, loss 257.3572336435318\n",
            "opimizers updated, step 35457 / 1435570, loss 256.19233828783035\n",
            "opimizers updated, step 35585 / 1435570, loss 263.5742329955101\n",
            "opimizers updated, step 35713 / 1435570, loss 256.54247111082077\n",
            "opimizers updated, step 35841 / 1435570, loss 263.04364562034607\n",
            "opimizers updated, step 35969 / 1435570, loss 254.08788245916367\n",
            "opimizers updated, step 36097 / 1435570, loss 256.4669260978699\n",
            "opimizers updated, step 36225 / 1435570, loss 253.70486268401146\n",
            "opimizers updated, step 36353 / 1435570, loss 253.16740065813065\n",
            "opimizers updated, step 36481 / 1435570, loss 263.05204117298126\n",
            "opimizers updated, step 36609 / 1435570, loss 262.53833961486816\n",
            "opimizers updated, step 36737 / 1435570, loss 258.2350164651871\n",
            "opimizers updated, step 36865 / 1435570, loss 251.8274965286255\n",
            "opimizers updated, step 36993 / 1435570, loss 260.18820011615753\n",
            "opimizers updated, step 37121 / 1435570, loss 256.36654901504517\n",
            "opimizers updated, step 37249 / 1435570, loss 264.86972975730896\n",
            "opimizers updated, step 37377 / 1435570, loss 259.1157814860344\n",
            "opimizers updated, step 37505 / 1435570, loss 254.89665108919144\n",
            "opimizers updated, step 37633 / 1435570, loss 259.78257632255554\n",
            "opimizers updated, step 37761 / 1435570, loss 250.1246975660324\n",
            "opimizers updated, step 37889 / 1435570, loss 255.07893866300583\n",
            "opimizers updated, step 38017 / 1435570, loss 257.15923368930817\n",
            "opimizers updated, step 38145 / 1435570, loss 252.42277878522873\n",
            "opimizers updated, step 38273 / 1435570, loss 261.15460580587387\n",
            "opimizers updated, step 38401 / 1435570, loss 259.93111580610275\n",
            "opimizers updated, step 38529 / 1435570, loss 251.3660900592804\n",
            "opimizers updated, step 38657 / 1435570, loss 261.1885269880295\n",
            "opimizers updated, step 38785 / 1435570, loss 257.3899847269058\n",
            "opimizers updated, step 38913 / 1435570, loss 262.4326641559601\n",
            "opimizers updated, step 39041 / 1435570, loss 256.6249117255211\n",
            "opimizers updated, step 39169 / 1435570, loss 246.67816072702408\n",
            "opimizers updated, step 39297 / 1435570, loss 257.36028200387955\n",
            "opimizers updated, step 39425 / 1435570, loss 255.45390617847443\n",
            "opimizers updated, step 39553 / 1435570, loss 250.645853638649\n",
            "opimizers updated, step 39681 / 1435570, loss 260.5438507795334\n",
            "opimizers updated, step 39809 / 1435570, loss 250.1903828382492\n",
            "opimizers updated, step 39937 / 1435570, loss 257.3433116674423\n",
            "opimizers updated, step 40065 / 1435570, loss 261.1711890101433\n",
            "opimizers updated, step 40193 / 1435570, loss 259.62088894844055\n",
            "opimizers updated, step 40321 / 1435570, loss 253.2185959815979\n",
            "opimizers updated, step 40449 / 1435570, loss 265.67864215373993\n",
            "opimizers updated, step 40577 / 1435570, loss 262.2776808142662\n",
            "opimizers updated, step 40705 / 1435570, loss 248.38312953710556\n",
            "opimizers updated, step 40833 / 1435570, loss 249.2921227812767\n",
            "opimizers updated, step 40961 / 1435570, loss 265.48381930589676\n",
            "opimizers updated, step 41089 / 1435570, loss 248.01734602451324\n",
            "opimizers updated, step 41217 / 1435570, loss 253.30824971199036\n",
            "opimizers updated, step 41345 / 1435570, loss 261.71022045612335\n",
            "opimizers updated, step 41473 / 1435570, loss 256.427139043808\n",
            "opimizers updated, step 41601 / 1435570, loss 250.33752143383026\n",
            "opimizers updated, step 41729 / 1435570, loss 254.3104332089424\n",
            "opimizers updated, step 41857 / 1435570, loss 245.8356778025627\n",
            "opimizers updated, step 41985 / 1435570, loss 256.50966012477875\n",
            "opimizers updated, step 42113 / 1435570, loss 260.60998022556305\n",
            "opimizers updated, step 42241 / 1435570, loss 253.91767489910126\n",
            "opimizers updated, step 42369 / 1435570, loss 262.8438394665718\n",
            "opimizers updated, step 42497 / 1435570, loss 250.4668487906456\n",
            "opimizers updated, step 42625 / 1435570, loss 254.1499000787735\n",
            "opimizers updated, step 42753 / 1435570, loss 256.8416247367859\n",
            "opimizers updated, step 42881 / 1435570, loss 261.45099568367004\n",
            "opimizers updated, step 43009 / 1435570, loss 253.0640464425087\n",
            "opimizers updated, step 43137 / 1435570, loss 255.19126969575882\n",
            "opimizers updated, step 43265 / 1435570, loss 252.82458698749542\n",
            "opimizers updated, step 43393 / 1435570, loss 251.760327398777\n",
            "opimizers updated, step 43521 / 1435570, loss 252.08781003952026\n",
            "opimizers updated, step 43649 / 1435570, loss 255.5711830854416\n",
            "opimizers updated, step 43777 / 1435570, loss 263.1238837838173\n",
            "opimizers updated, step 43905 / 1435570, loss 256.66440296173096\n",
            "opimizers updated, step 44033 / 1435570, loss 259.2925986647606\n",
            "opimizers updated, step 44161 / 1435570, loss 263.1366513967514\n",
            "opimizers updated, step 44289 / 1435570, loss 258.78998202085495\n",
            "opimizers updated, step 44417 / 1435570, loss 258.4169384241104\n",
            "opimizers updated, step 44545 / 1435570, loss 250.95971995592117\n",
            "opimizers updated, step 44673 / 1435570, loss 254.7920137643814\n",
            "opimizers updated, step 44801 / 1435570, loss 258.06247770786285\n",
            "opimizers updated, step 44929 / 1435570, loss 248.7523713707924\n",
            "opimizers updated, step 45057 / 1435570, loss 263.34799259901047\n",
            "opimizers updated, step 45185 / 1435570, loss 265.5625972747803\n",
            "opimizers updated, step 45313 / 1435570, loss 255.64812886714935\n",
            "opimizers updated, step 45441 / 1435570, loss 254.01068991422653\n",
            "opimizers updated, step 45569 / 1435570, loss 242.8234804868698\n",
            "opimizers updated, step 45697 / 1435570, loss 261.9319005012512\n",
            "opimizers updated, step 45825 / 1435570, loss 249.31207764148712\n",
            "opimizers updated, step 45953 / 1435570, loss 252.13799703121185\n",
            "opimizers updated, step 46081 / 1435570, loss 250.96330797672272\n",
            "opimizers updated, step 46209 / 1435570, loss 250.6690069437027\n",
            "opimizers updated, step 46337 / 1435570, loss 253.05471378564835\n",
            "opimizers updated, step 46465 / 1435570, loss 252.98733240365982\n",
            "opimizers updated, step 46593 / 1435570, loss 251.368561565876\n",
            "opimizers updated, step 46721 / 1435570, loss 252.58011734485626\n",
            "opimizers updated, step 46849 / 1435570, loss 246.6991360783577\n",
            "opimizers updated, step 46977 / 1435570, loss 258.2184063196182\n",
            "opimizers updated, step 47105 / 1435570, loss 253.19346570968628\n",
            "opimizers updated, step 47233 / 1435570, loss 251.98540657758713\n",
            "opimizers updated, step 47361 / 1435570, loss 245.00585567951202\n",
            "opimizers updated, step 47489 / 1435570, loss 247.72720247507095\n",
            "opimizers updated, step 47617 / 1435570, loss 256.0835156440735\n",
            "opimizers updated, step 47745 / 1435570, loss 260.85695308446884\n",
            "opimizers updated, step 47873 / 1435570, loss 251.7898080945015\n",
            "opimizers updated, step 48001 / 1435570, loss 253.4450542330742\n",
            "opimizers updated, step 48129 / 1435570, loss 248.7845184803009\n",
            "opimizers updated, step 48257 / 1435570, loss 248.2433686852455\n",
            "opimizers updated, step 48385 / 1435570, loss 253.72906005382538\n",
            "opimizers updated, step 48513 / 1435570, loss 250.14497381448746\n",
            "opimizers updated, step 48641 / 1435570, loss 248.36500388383865\n",
            "opimizers updated, step 48769 / 1435570, loss 258.6566017270088\n",
            "opimizers updated, step 48897 / 1435570, loss 244.77760475873947\n",
            "opimizers updated, step 49025 / 1435570, loss 243.8234776854515\n",
            "opimizers updated, step 49153 / 1435570, loss 258.0282884836197\n",
            "opimizers updated, step 49281 / 1435570, loss 251.2576858997345\n",
            "opimizers updated, step 49409 / 1435570, loss 258.2504963874817\n",
            "opimizers updated, step 49537 / 1435570, loss 259.8857194185257\n",
            "opimizers updated, step 49665 / 1435570, loss 246.51896411180496\n",
            "opimizers updated, step 49793 / 1435570, loss 254.86508536338806\n",
            "opimizers updated, step 49921 / 1435570, loss 252.55429422855377\n",
            "opimizers updated, step 50049 / 1435570, loss 260.0285520553589\n",
            "opimizers updated, step 50177 / 1435570, loss 260.0904445052147\n",
            "opimizers updated, step 50305 / 1435570, loss 245.2421623468399\n",
            "opimizers updated, step 50433 / 1435570, loss 252.97119390964508\n",
            "opimizers updated, step 50561 / 1435570, loss 252.93154138326645\n",
            "opimizers updated, step 50689 / 1435570, loss 263.18287909030914\n",
            "opimizers updated, step 50817 / 1435570, loss 262.7990902662277\n",
            "opimizers updated, step 50945 / 1435570, loss 258.79027116298676\n",
            "opimizers updated, step 51073 / 1435570, loss 245.8358090519905\n",
            "opimizers updated, step 51201 / 1435570, loss 254.22812056541443\n",
            "opimizers updated, step 51329 / 1435570, loss 264.3845644593239\n",
            "opimizers updated, step 51457 / 1435570, loss 247.19852685928345\n",
            "opimizers updated, step 51585 / 1435570, loss 247.39987033605576\n",
            "opimizers updated, step 51713 / 1435570, loss 264.72408854961395\n",
            "opimizers updated, step 51841 / 1435570, loss 257.39593827724457\n",
            "opimizers updated, step 51969 / 1435570, loss 253.52738118171692\n",
            "opimizers updated, step 52097 / 1435570, loss 260.1534643173218\n",
            "opimizers updated, step 52225 / 1435570, loss 254.02074468135834\n",
            "opimizers updated, step 52353 / 1435570, loss 249.88506907224655\n",
            "opimizers updated, step 52481 / 1435570, loss 249.29211163520813\n",
            "opimizers updated, step 52609 / 1435570, loss 266.237716794014\n",
            "opimizers updated, step 52737 / 1435570, loss 251.23530846834183\n",
            "opimizers updated, step 52865 / 1435570, loss 258.12739300727844\n",
            "opimizers updated, step 52993 / 1435570, loss 256.2248129248619\n",
            "opimizers updated, step 53121 / 1435570, loss 252.182215154171\n",
            "opimizers updated, step 53249 / 1435570, loss 254.11969715356827\n",
            "opimizers updated, step 53377 / 1435570, loss 255.4454219341278\n",
            "opimizers updated, step 53505 / 1435570, loss 261.8577898144722\n",
            "opimizers updated, step 53633 / 1435570, loss 257.6599555015564\n",
            "opimizers updated, step 53761 / 1435570, loss 252.59629482030869\n",
            "opimizers updated, step 53889 / 1435570, loss 256.15893936157227\n",
            "opimizers updated, step 54017 / 1435570, loss 252.96879506111145\n",
            "opimizers updated, step 54145 / 1435570, loss 256.25021332502365\n",
            "opimizers updated, step 54273 / 1435570, loss 255.7310101389885\n",
            "opimizers updated, step 54401 / 1435570, loss 258.5171146392822\n",
            "opimizers updated, step 54529 / 1435570, loss 252.35357296466827\n",
            "opimizers updated, step 54657 / 1435570, loss 243.50596964359283\n",
            "opimizers updated, step 54785 / 1435570, loss 252.8598654270172\n",
            "opimizers updated, step 54913 / 1435570, loss 260.0671660900116\n",
            "opimizers updated, step 55041 / 1435570, loss 254.05826711654663\n",
            "opimizers updated, step 55169 / 1435570, loss 250.6057626605034\n",
            "opimizers updated, step 55297 / 1435570, loss 259.1722931265831\n",
            "opimizers updated, step 55425 / 1435570, loss 244.6373987197876\n",
            "opimizers updated, step 55553 / 1435570, loss 245.62317037582397\n",
            "opimizers updated, step 55681 / 1435570, loss 250.47354781627655\n",
            "opimizers updated, step 55809 / 1435570, loss 246.6135379076004\n",
            "opimizers updated, step 55937 / 1435570, loss 254.0536447763443\n",
            "opimizers updated, step 56065 / 1435570, loss 242.73899495601654\n",
            "opimizers updated, step 56193 / 1435570, loss 251.32798290252686\n",
            "opimizers updated, step 56321 / 1435570, loss 254.3754130601883\n",
            "opimizers updated, step 56449 / 1435570, loss 251.57364827394485\n",
            "opimizers updated, step 56577 / 1435570, loss 244.51224690675735\n",
            "opimizers updated, step 56705 / 1435570, loss 253.6628818511963\n",
            "opimizers updated, step 56833 / 1435570, loss 253.37444067001343\n",
            "opimizers updated, step 56961 / 1435570, loss 252.47051864862442\n",
            "opimizers updated, step 57089 / 1435570, loss 257.94826662540436\n",
            "opimizers updated, step 57217 / 1435570, loss 256.91301131248474\n",
            "opimizers updated, step 57345 / 1435570, loss 250.31470572948456\n",
            "opimizers updated, step 57473 / 1435570, loss 267.0030806660652\n",
            "opimizers updated, step 57601 / 1435570, loss 251.66970324516296\n",
            "opimizers updated, step 57729 / 1435570, loss 248.93891197443008\n",
            "opimizers updated, step 57857 / 1435570, loss 253.22646579146385\n",
            "opimizers updated, step 57985 / 1435570, loss 246.34666007757187\n",
            "opimizers updated, step 58113 / 1435570, loss 251.87286031246185\n",
            "opimizers updated, step 58241 / 1435570, loss 254.43009847402573\n",
            "opimizers updated, step 58369 / 1435570, loss 249.62975758314133\n",
            "opimizers updated, step 58497 / 1435570, loss 258.71549862623215\n",
            "opimizers updated, step 58625 / 1435570, loss 240.42824804782867\n",
            "opimizers updated, step 58753 / 1435570, loss 247.08786886930466\n",
            "opimizers updated, step 58881 / 1435570, loss 245.44138151407242\n",
            "opimizers updated, step 59009 / 1435570, loss 244.15169990062714\n",
            "opimizers updated, step 59137 / 1435570, loss 254.8560715317726\n",
            "opimizers updated, step 59265 / 1435570, loss 245.67689126729965\n",
            "opimizers updated, step 59393 / 1435570, loss 244.84929084777832\n",
            "opimizers updated, step 59521 / 1435570, loss 252.93180012702942\n",
            "opimizers updated, step 59649 / 1435570, loss 248.3527317047119\n",
            "opimizers updated, step 59777 / 1435570, loss 245.43441861867905\n",
            "opimizers updated, step 59905 / 1435570, loss 255.59387707710266\n",
            "opimizers updated, step 60033 / 1435570, loss 253.5181811451912\n",
            "opimizers updated, step 60161 / 1435570, loss 248.60385930538177\n",
            "opimizers updated, step 60289 / 1435570, loss 249.69126325845718\n",
            "opimizers updated, step 60417 / 1435570, loss 254.78572219610214\n",
            "opimizers updated, step 60545 / 1435570, loss 245.52997201681137\n",
            "opimizers updated, step 60673 / 1435570, loss 249.75990343093872\n",
            "opimizers updated, step 60801 / 1435570, loss 252.0479701757431\n",
            "opimizers updated, step 60929 / 1435570, loss 249.91090232133865\n",
            "opimizers updated, step 61057 / 1435570, loss 253.39102935791016\n",
            "opimizers updated, step 61185 / 1435570, loss 248.3645870089531\n",
            "opimizers updated, step 61313 / 1435570, loss 250.16648292541504\n",
            "opimizers updated, step 61441 / 1435570, loss 244.18060529232025\n",
            "opimizers updated, step 61569 / 1435570, loss 241.26750993728638\n",
            "opimizers updated, step 61697 / 1435570, loss 254.46100234985352\n",
            "opimizers updated, step 61825 / 1435570, loss 259.7794796824455\n",
            "opimizers updated, step 61953 / 1435570, loss 240.09619319438934\n",
            "opimizers updated, step 62081 / 1435570, loss 245.06213915348053\n",
            "opimizers updated, step 62209 / 1435570, loss 250.26550233364105\n",
            "opimizers updated, step 62337 / 1435570, loss 244.0626438856125\n",
            "opimizers updated, step 62465 / 1435570, loss 261.82344526052475\n",
            "opimizers updated, step 62593 / 1435570, loss 243.35847091674805\n",
            "opimizers updated, step 62721 / 1435570, loss 253.1798220872879\n",
            "opimizers updated, step 62849 / 1435570, loss 257.8310688138008\n",
            "opimizers updated, step 62977 / 1435570, loss 251.3334811925888\n",
            "opimizers updated, step 63105 / 1435570, loss 249.9425396323204\n",
            "opimizers updated, step 63233 / 1435570, loss 249.084088742733\n",
            "opimizers updated, step 63361 / 1435570, loss 252.19929778575897\n",
            "opimizers updated, step 63489 / 1435570, loss 256.68096059560776\n",
            "opimizers updated, step 63617 / 1435570, loss 252.64743584394455\n",
            "opimizers updated, step 63745 / 1435570, loss 248.63439065217972\n",
            "opimizers updated, step 63873 / 1435570, loss 254.67988973855972\n",
            "opimizers updated, step 64001 / 1435570, loss 252.9620418548584\n",
            "opimizers updated, step 64129 / 1435570, loss 248.43290543556213\n",
            "opimizers updated, step 64257 / 1435570, loss 258.377785384655\n",
            "opimizers updated, step 64385 / 1435570, loss 247.74099388718605\n",
            "opimizers updated, step 64513 / 1435570, loss 248.76825326681137\n",
            "opimizers updated, step 64641 / 1435570, loss 251.8603568971157\n",
            "opimizers updated, step 64769 / 1435570, loss 243.10101762413979\n",
            "opimizers updated, step 64897 / 1435570, loss 238.63006526231766\n",
            "opimizers updated, step 65025 / 1435570, loss 247.0194782614708\n",
            "opimizers updated, step 65153 / 1435570, loss 250.58122205734253\n",
            "opimizers updated, step 65281 / 1435570, loss 244.28182643651962\n",
            "opimizers updated, step 65409 / 1435570, loss 257.35401207208633\n",
            "opimizers updated, step 65537 / 1435570, loss 247.05082374811172\n",
            "opimizers updated, step 65665 / 1435570, loss 242.86418640613556\n",
            "opimizers updated, step 65793 / 1435570, loss 250.2489576935768\n",
            "opimizers updated, step 65921 / 1435570, loss 244.7521654367447\n",
            "opimizers updated, step 66049 / 1435570, loss 258.05976873636246\n",
            "opimizers updated, step 66177 / 1435570, loss 250.6017256975174\n",
            "opimizers updated, step 66305 / 1435570, loss 249.2214344739914\n",
            "opimizers updated, step 66433 / 1435570, loss 245.9599226117134\n",
            "opimizers updated, step 66561 / 1435570, loss 246.55443066358566\n",
            "opimizers updated, step 66689 / 1435570, loss 250.6606389284134\n",
            "opimizers updated, step 66817 / 1435570, loss 249.93223410844803\n",
            "opimizers updated, step 66945 / 1435570, loss 248.02974086999893\n",
            "opimizers updated, step 67073 / 1435570, loss 253.8069036602974\n",
            "opimizers updated, step 67201 / 1435570, loss 251.84231519699097\n",
            "opimizers updated, step 67329 / 1435570, loss 250.63936311006546\n",
            "opimizers updated, step 67457 / 1435570, loss 251.91868752241135\n",
            "opimizers updated, step 67585 / 1435570, loss 258.8863590955734\n",
            "opimizers updated, step 67713 / 1435570, loss 253.40384656190872\n",
            "opimizers updated, step 67841 / 1435570, loss 245.48666369915009\n",
            "opimizers updated, step 67969 / 1435570, loss 247.3494564294815\n",
            "opimizers updated, step 68097 / 1435570, loss 250.2826428413391\n",
            "opimizers updated, step 68225 / 1435570, loss 241.3713060617447\n",
            "opimizers updated, step 68353 / 1435570, loss 256.15314650535583\n",
            "opimizers updated, step 68481 / 1435570, loss 247.93210643529892\n",
            "opimizers updated, step 68609 / 1435570, loss 244.82380264997482\n",
            "opimizers updated, step 68737 / 1435570, loss 242.25718915462494\n",
            "opimizers updated, step 68865 / 1435570, loss 246.3178921341896\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "\n",
        "completed_steps = 0\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "    train_loss_sum = 0\n",
        "    eval_loss_sum = 0\n",
        "    loss_buf = 0\n",
        "\n",
        "    print('model training')\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        completed_steps += 1\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        \n",
        "        loss_buf += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "        loss.backward()\n",
        "\n",
        "        if step % optimizer_steps == 0 or step == len(train_dataset) - 1:\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            print(f'opimizers updated, step {completed_steps} / {epoch_num * len(train_dataloader)}, loss {loss_buf}')\n",
        "            loss_buf = 0\n",
        "\n",
        "    print('model evaluating')\n",
        "    model.eval()\n",
        "\n",
        "    gen_kwargs = {\n",
        "        'max_length': 256,\n",
        "        'num_beams': 3\n",
        "    }\n",
        "\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        batch = batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            \n",
        "            eval_loss_sum += loss.item()\n",
        "\n",
        "            generated_tokens = model.generate(\n",
        "                batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                **gen_kwargs,\n",
        "            )\n",
        "\n",
        "            labels = batch[\"labels\"]\n",
        "\n",
        "            labels = labels.cpu().numpy()\n",
        "            generated_tokens = generated_tokens.cpu().numpy()\n",
        "\n",
        "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "            metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
        "    \n",
        "    eval_result = metric.compute(use_stemmer=True)\n",
        "    metrics.append(eval_result)\n",
        "    result = {key: round(value.mid.fmeasure * 100, 4) for key, value in eval_result.items()}\n",
        "\n",
        "    for step, batch in enumerate(subset_dataloader):\n",
        "        batch = batch.to(device)\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "\n",
        "    train_losses_epoch.append(train_loss_sum)\n",
        "    eval_losses_epoch.append(eval_loss_sum)\n",
        "\n",
        "    print(f'evaluating metrics: {result}')\n",
        "    print(f'epoch {epoch + 1} / {epoch_num} completed, train_loss: {train_loss_sum}, eval loss: {eval_loss_sum}')\n",
        "\n",
        "print('training completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzGKE1f6jJo8"
      },
      "outputs": [],
      "source": [
        "# Saving model to disk for later reuse\n",
        "\n",
        "torch.save(model, 'content/model/model.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjZWh_a8jJo9"
      },
      "outputs": [],
      "source": [
        "# Loading model from disk for reuse\n",
        "\n",
        "model = torch.load('content/model/model.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6ZTl2lBjJo9",
        "outputId": "ded9317e-46fb-4d7f-b27a-1fc44c9329e4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1224x432 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training and evaluation losses by epoch\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(17,6))\n",
        "\n",
        "ax[0].plot(train_losses_epoch)\n",
        "ax[0].set_title('train losses')\n",
        "ax[1].plot(eval_losses_epoch)\n",
        "ax[1].set_title('eval losses');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4aKILvBjJo-",
        "outputId": "510b6e7c-f0c1-4b66-b918-60deb6f47b1d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training loss graphic\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(train_losses)\n",
        "plt.legend(['training'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQlgoyX6jJo-",
        "outputId": "afb32fb5-91e9-4246-c685-601509dcb1fe"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Metric graphics\n",
        "\n",
        "rouge1 = []\n",
        "rouge2 = []\n",
        "rougeL = []\n",
        "rougeLsum = []\n",
        "\n",
        "for metric_i in metrics:\n",
        "    metric = {key: value.mid.fmeasure for key, value in metric_i.items()}\n",
        "    rouge1.append(metric['rouge1'])\n",
        "    rouge2.append(metric['rouge2'])\n",
        "    rougeL.append(metric['rougeL'])\n",
        "    rougeLsum.append(metric['rougeLsum'])\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(15,15))\n",
        "\n",
        "ax[0][0].plot(rouge1)\n",
        "ax[0][0].set_title('rouge1')\n",
        "\n",
        "ax[0][1].plot(rouge2)\n",
        "ax[0][1].set_title('rouge2')\n",
        "\n",
        "ax[1][0].plot(rougeL)\n",
        "ax[1][0].set_title('rougeL')\n",
        "\n",
        "ax[1][1].plot(rougeLsum)\n",
        "ax[1][1].set_title('rougeLsum');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvw-KHExjJo_"
      },
      "outputs": [],
      "source": [
        "some_summaries = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MYjILNvjJo_",
        "outputId": "ecaeda6c-188d-41f1-a2a0-ed9f51d39b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing model\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'add_batch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-fee3390dca98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0msome_summaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'step {step + 1} / {len(test_dataloader)} completed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'add_batch'"
          ]
        }
      ],
      "source": [
        "print('testing model')\n",
        "\n",
        "gen_kwargs = {\n",
        "    'max_length': 256,\n",
        "    'num_beams': 3\n",
        "}\n",
        "\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    batch = batch.to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = model.generate(\n",
        "            batch['input_ids'],\n",
        "            attention_mask = batch['attention_mask'],\n",
        "            **gen_kwargs                         \n",
        "        )\n",
        "\n",
        "        labels = batch['labels']\n",
        "\n",
        "        labels = labels.cpu().numpy()\n",
        "        generated_tokens = generated_tokens.cpu().numpy()\n",
        "\n",
        "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "        if step == 0 or step == 50 or step == 60 or step == 74:\n",
        "            some_summaries.append((decoded_preds, decoded_labels))\n",
        "            \n",
        "        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "        print(f'step {step + 1} / {len(test_dataloader)} completed')\n",
        "\n",
        "test_result = metric.compute(use_stemmer=True)\n",
        "result = {key: round(value.mid.fmeasure * 100, 4) for key, value in test_result.items()}\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrD196IKjJo_",
        "outputId": "78f454cf-4c6d-42c6-d6e1-d979c9a30120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rouge1': 42.4506, 'rouge2': 19.9627, 'rougeL': 29.8358, 'rougeLsum': 39.7059}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr-XNwhHjJpA",
        "outputId": "ee4f644b-799c-4ab7-c05d-e64b50f9162c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred\n",
            "James Best was best known for his role on \"The Dukes of Hazzard\"\n",
            "He died in hospice in Hickory, North Carolina, of complications from pneumonia.\n",
            "label\n",
            "James Best, who played the sheriff on \"The Dukes of Hazzard,\" died Monday at 88.\n",
            "\"Hazzard\" ran from 1979 to 1985 and was among the most popular shows on TV.\n",
            "\n",
            "pred\n",
            "Dr. Anthony Moschetto, 54, pleads not guilty to all charges against him.\n",
            "He is charged in what authorities say was a failed scheme to have another doctor hurt or killed.\n",
            "Two other men are accused of being accomplices in the plot.\n",
            "label\n",
            "A lawyer for Dr. Anthony Moschetto says the charges against him are baseless.\n",
            "Moschetto, 54, was arrested for selling drugs and weapons, prosecutors say.\n",
            "Authorities allege Moschetto hired accomplices to burn down the practice of former associate.\n",
            "\n",
            "pred\n",
            "James Best was best known for his portrayal of bumbling sheriff Rosco P. Coltrane on \"The Dukes of Hazzard\"\n",
            "Best died Monday after a brief illness.\n",
            "label\n",
            "James Best, who played the sheriff on \"The Dukes of Hazzard,\" died Monday at 88.\n",
            "\"Hazzard\" ran from 1979 to 1985 and was among the most popular shows on TV.\n",
            "\n",
            "pred\n",
            "Dr. Anthony Moschetto, 54, pleads not guilty to all charges.\n",
            "He is accused of conspiracy, conspiracy, burglary, arson, criminal prescription sale and weapons.\n",
            "label\n",
            "A lawyer for Dr. Anthony Moschetto says the charges against him are baseless.\n",
            "Moschetto, 54, was arrested for selling drugs and weapons, prosecutors say.\n",
            "Authorities allege Moschetto hired accomplices to burn down the practice of former associate.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for preds, labels in some_summaries:\n",
        "    for pred, label in zip(preds, labels):\n",
        "        print('pred')\n",
        "        print(pred)\n",
        "        print('label')\n",
        "        print(label)\n",
        "        print()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhldxBbwjJpA",
        "outputId": "b975d339-ac9c-4015-8745-f41fd042861e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(['James Best was best known for his role on \"The Dukes of Hazzard\"\\nHe died in hospice in Hickory, North Carolina, of complications from pneumonia.',\n",
              "   'Dr. Anthony Moschetto, 54, pleads not guilty to all charges against him.\\nHe is charged in what authorities say was a failed scheme to have another doctor hurt or killed.\\nTwo other men are accused of being accomplices in the plot.'],\n",
              "  ['James Best, who played the sheriff on \"The Dukes of Hazzard,\" died Monday at 88.\\n\"Hazzard\" ran from 1979 to 1985 and was among the most popular shows on TV.',\n",
              "   'A lawyer for Dr. Anthony Moschetto says the charges against him are baseless.\\nMoschetto, 54, was arrested for selling drugs and weapons, prosecutors say.\\nAuthorities allege Moschetto hired accomplices to burn down the practice of former associate.'])]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "some_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4HtIcvkjJpA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "VVs871VXSI9n",
        "TUTm4YUBjJoy",
        "xCxS_ntejJoy",
        "O6SIhad3jJo2"
      ],
      "machine_shape": "hm",
      "name": "bart_pretrain.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}